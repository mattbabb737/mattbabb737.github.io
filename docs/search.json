[
  {
    "objectID": "posts-listing-page.html",
    "href": "posts-listing-page.html",
    "title": "My Portfolio",
    "section": "",
    "text": "Web Scraping\n\n\n\nQuarto\n\nR\n\n\n\nExtracting, cleaning, and organizing data from multiple web pages into a structured format.\n\n\n\nMatt Babb\n\n\nJun 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative Art\n\n\n\nQuarto\n\nR\n\n\n\nExplore algorithmic aesthetics by using iterative functions to create mathematical art.\n\n\n\nMatt Babb\n\n\nJun 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nWriting Efficient Functions\n\n\n\nQuarto\n\nR\n\n\n\nExamples of computationally sensible and user-friendly function writing.\n\n\n\nMatt Babb\n\n\nJun 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeditation and retrospective time estimation\n\n\n\nQuarto\n\nR\n\nCSS\n\nCSL\n\n\n\nAn empirical study investigating the effect of mindfulness meditation on how we perceive the flow of time.\n\n\n\nMatt Babb, J.P. Boiler, James Elliott, James Antony\n\n\nJun 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nJSON Data and API‚Äôs\n\n\n\nQuarto\n\nR\n\nJSON\n\n\n\nAccess and parse API-based JSON data in R.\n\n\n\nMatt Babb\n\n\nJun 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced visualizations\n\n\n\nQuarto\n\nR\n\n\n\nExploring ideas about how to make visualizations both more appealing and more functional.\n\n\n\nMatt Babb\n\n\nMay 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto dashboards (dynamic)\n\n\n\nQuarto\n\nR\n\nShiny\n\n\n\nTaking static dashboards and making them interactive using Shiny.\n\n\n\nMatt Babb\n\n\nMay 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto dashboards (static)\n\n\n\nQuarto\n\nR\n\n\n\nMaking a Quarto dashboard with pages, tabs, and plots.\n\n\n\nMatt Babb\n\n\nMay 5, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Matt Babb",
    "section": "",
    "text": "Hello, all! Thank you for finding your way to my portfolio. Here you‚Äôll find numerous posts exploring many techniques and features of statistical computing in R, as well as my Senior Project. These posts were built from lab assignments taught in STAT 541 by Dr.¬†Allison Theobold at Cal Poly, San Luis Obispo, CA. Enjoy!"
  },
  {
    "objectID": "posts/2025-05-05-advanced-visualizations/index.html",
    "href": "posts/2025-05-05-advanced-visualizations/index.html",
    "title": "Advanced visualizations",
    "section": "",
    "text": "Create a Quarto file for ALL Lab 2 (no separate files for Parts 1 and 2).\n\nMake sure your final file is carefully formatted, so that each analysis is clear and concise.\nBe sure your knitted .html file shows all your source code, including any function definitions."
  },
  {
    "objectID": "posts/2025-05-05-advanced-visualizations/index.html#dissecting-a-bad-visualization",
    "href": "posts/2025-05-05-advanced-visualizations/index.html#dissecting-a-bad-visualization",
    "title": "Advanced visualizations",
    "section": "Dissecting a Bad Visualization",
    "text": "Dissecting a Bad Visualization\nBelow is an example of a less-than-ideal visualization from the collection linked above. It comes to us from data provided for the Wellcome Global Monitor 2018 report by the Gallup World Poll:\n\n\nWhile there are certainly issues with this image, do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nIt appears that this image is trying to represent the proportions of people in each country that answered affirmatively to the statement ‚ÄúVaccines are safe‚Äù. That data come from the year 2018, and are grouped by global region. We can see that the median affirmative answer in each global region increases from the bottom of the plot to the top.\n\nList the variables that appear to be displayed in this visualization. Hint: Variables refer to columns in the data.\n\nVariables include:\n\nPercentage of people who believe that vaccines are safe\nGlobal region\nRegion medians\nCountries\n\n\nNow that you‚Äôre versed in the grammar of graphics (e.g., ggplot), list the aesthetics used and which variables are mapped to each.\n\nThe aesthetics map to variables in the following ways:\n\nx is mapped to proportion of the population that believes that vaccines are safe\ny is mapped to‚Ä¶nothing?\ncolor is mapped to goblal region\nlabel is mapped individual country names\nEach point represents the proportion of a country‚Äôs pro-vacc‚Äôers, and is drawn with geom_point()\n\nVertical lines are added using geom_vline() to show regional medians, which increase as one looks higher in the plot\n\n\nWhat type of graph would you call this? Meaning, what geom would you use to produce this plot?\n\nThis appears to be a scatterplot that also creates a quasi-faceting effect by grouping countries based on region, and then separating them vertically depending on the median proportion of belief in vaccine safety in each global region. I would use geom_point() to create this plot.\n\nProvide at least four problems or changes that would improve this graph. Please format your changes as bullet points!\n\nFour ways to improve this plot are:\n\nEliminate the legend\nDouble-code the points to further distinguish them beyond color\nEliminate the appearance of the y-axis in each facet representing something quantitative\nMake points clickable so that one can see percentages for individual countries\n[Bonus] I would add a search bar so that someone can search for individual countries"
  },
  {
    "objectID": "posts/2025-05-05-advanced-visualizations/index.html#improving-the-bad-visualization",
    "href": "posts/2025-05-05-advanced-visualizations/index.html#improving-the-bad-visualization",
    "title": "Advanced visualizations",
    "section": "Improving the Bad Visualization",
    "text": "Improving the Bad Visualization\nThe data for the Wellcome Global Monitor 2018 report can be downloaded at the following site: https://wellcome.ac.uk/reports/wellcome-global-monitor/2018\n\nThere are two worksheets in the downloaded dataset file. You may need to read them in separately, but you may also just use one if it suffices.\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\n\n\nwgm_raw &lt;- read_excel(\"wgm2018-dataset-crosstabs-all-countries.xlsx\", skip = 2)\n\n\nwgm_clean &lt;- wgm_raw %&gt;%\n  tidyr::fill(Question) \n\n\nregion_map &lt;- list(\n  \"Asia\" = c(\"Afghanistan\", \"Bangladesh\", \"India\", \"Iran\", \"Nepal\", \"Pakistan\", \"Sri Lanka\",\n             \"Cambodia\", \"Indonesia\", \"Laos\", \"Malaysia\", \"Myanmar\", \"Philippines\", \"Singapore\",\n             \"Thailand\", \"Vietnam\", \"China\", \"Japan\", \"Mongolia\", \"South Korea\", \"Taiwan\"),\n  \"Middle East and North Africa\" = c(\"Algeria\", \"Egypt\", \"Libya\", \"Morocco\", \"Tunisia\", \"Iraq\",\n             \"Israel\", \"Jordan\", \"Kuwait\", \"Lebanon\", \"Palestinian Territories\", \"Saudi Arabia\",\n             \"Turkey\", \"United Arab Emirates\", \"Yemen\"),\n  \"Sub-Saharan Africa\" = c(\"Burundi\", \"Comoros\", \"Ethiopia\", \"Kenya\", \"Madagascar\", \"Malawi\", \n             \"Mauritius\", \"Mozambique\", \"Rwanda\", \"Tanzania\", \"Uganda\", \"Zambia\", \"Zimbabwe\",\n             \"Benin\", \"Burkina Faso\", \"Ghana\", \"Guinea\", \"Ivory Coast\", \"Liberia\", \"Mali\", \n             \"Mauritania\", \"Niger\", \"Nigeria\", \"Senegal\", \"Sierra Leone\", \"The Gambia\", \"Togo\",\n             \"Botswana\", \"Namibia\", \"South Africa\", \"Eswatini\", \"Cameroon\", \"Chad\", \n             \"Republic of the Congo\", \"Gabon\"),\n  \"Americas\" = c(\"Costa Rica\", \"Dominican Republic\", \"El Salvador\", \"Guatemala\", \"Haiti\", \n             \"Honduras\", \"Mexico\", \"Nicaragua\", \"Panama\", \"Argentina\", \"Bolivia\", \"Brazil\", \n             \"Chile\", \"Colombia\", \"Ecuador\", \"Paraguay\", \"Peru\", \"Uruguay\", \"Venezuela\", \n             \"Canada\", \"United States\"),\n  \"Europe\" = c(\"Denmark\", \"Estonia\", \"Finland\", \"Iceland\", \"Ireland\", \"Latvia\", \"Lithuania\", \n             \"Norway\", \"Sweden\", \"United Kingdom\", \"Albania\", \"Bosnia and Herzegovina\", \n             \"Croatia\", \"Cyprus\", \"Greece\", \"Italy\", \"Malta\", \"North Macedonia\", \"Montenegro\", \n             \"Portugal\", \"Serbia\", \"Slovenia\", \"Spain\", \"Austria\", \"Belgium\", \"France\", \n             \"Germany\", \"Luxembourg\", \"Netherlands\", \"Switzerland\"),\n  \"Former Soviet Union\" = c(\"Armenia\", \"Azerbaijan\", \"Georgia\", \"Kazakhstan\", \"Kyrgyzstan\", \n             \"Tajikistan\", \"Turkmenistan\", \"Uzbekistan\", \"Belarus\", \"Bulgaria\", \n             \"Czech Republic\", \"Hungary\", \"Moldova\", \"Poland\", \"Romania\", \"Russia\", \n             \"Slovakia\", \"Ukraine\")\n)\n\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\n\nCode\nwgm_agree &lt;- wgm_clean %&gt;%\n  filter(\n    Question == \"Q25 Do you strongly or somewhat agree, strongly or somewhat disagree or neither agree nor disagree with the following statement? Vaccines are safe.\",\n    Response %in% c(\"Strongly agree\", \"Somewhat agree\")\n  ) %&gt;%\n  group_by(Country) %&gt;%\n  summarise(\n    percent_agree = sum(`Column N %...4`, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(percent_agree))\n\n\ncountry_to_region &lt;- unlist(lapply(names(region_map), function(region) {\n  setNames(rep(region, length(region_map[[region]])), region_map[[region]])\n})\n)\n\n\nwgm_agree &lt;- wgm_agree %&gt;%\n  mutate(Region = country_to_region[Country],\n         Region = ifelse(is.na(Region), \"Other/Unclassified\", Region))\n\n\n\n\nCode\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(forcats)\nlibrary(ggridges)\nlibrary(crosstalk)\nlibrary(bslib)\nlibrary(htmltools)\n\n\nwgm_agree_filtered &lt;- wgm_agree %&gt;%\n  filter(Region != \"Unclassified\") %&gt;%\n  mutate(Region = fct_reorder(Region, percent_agree, .fun = median))\n\n\nshared_data &lt;- SharedData$new(wgm_agree_filtered)\n\n\n# Base plot\np &lt;- ggplot(shared_data, aes(x = percent_agree, y = Region, fill = Region)) +\n  geom_density_ridges(scale = 1.2, alpha = 0.6, color = \"white\") +\n  geom_point(\n    aes(text = paste(\"Country:\", Country, \"&lt;br&gt;Score:\",\n                     round(percent_agree * 100, 1), \"%\")),\n    position = position_jitter(height = 0.1),\n    size = 2,\n    color = \"black\"\n  ) +\n  scale_x_continuous(\n    limits = c(0.2, 1.0),\n    labels = scales::percent_format(accuracy = 1)\n  ) +\n  labs(\n    x = \"Agreement\",\n    y = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    legend.position = \"none\"\n  )\n\n\n# Interactive plot\nplotly_obj &lt;- ggplotly(p, tooltip = \"text\") %&gt;%\n  layout(\n    title = list(\n      text = \"&lt;b&gt;Belief that Vaccines are Safe by Region&lt;/b&gt;\",\n      x = 0,\n      xanchor = \"left\",\n      y = 0.95,\n      yanchor = \"top\",\n      font = list(size = 20, family = \"Arial\", color = \"black\")\n    )\n  )\n\n\n# Combine search bar and plot (stacked vertically)\nbrowsable(\n  tagList(\n    filter_select(id = \"country\",\n                  label = \"Select Country\",\n                  sharedData = shared_data,\n                  group = ~Country),\n    plotly_obj\n  )\n)\n\n\n\nSelect Country"
  },
  {
    "objectID": "posts/2025-05-05-advanced-visualizations/index.html#second-data-visualization-improvement",
    "href": "posts/2025-05-05-advanced-visualizations/index.html#second-data-visualization-improvement",
    "title": "Advanced visualizations",
    "section": "Second Data Visualization Improvement",
    "text": "Second Data Visualization Improvement\nFor this second plot, you must select a plot that uses maps so you can demonstrate your proficiency with the leaflet package!\n\nSelect a data visualization in the report that you think could be improved. Be sure to cite both the page number and figure title. Do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\n\nOriginal image (Source: Wellcome Global Monitor, 2018, p.¬†92.)\n This plot intends to show the net percentages of people in each global region who believe that technology will lead to an increase in jobs within their country in the next five years. Global regions are listed, as well as an average for the world. Bars are colored to indicate positive or negative net increase, and a line at x = 0 is shown.\n\nList the variables that appear to be displayed in this visualization.\n\nVariables include:\n\nGlobal regions\nNet impact score of technology on jobs in the next five years (percentage of people who said ‚ÄúIncrease‚Äù minus percentage of people who said ‚ÄúDecrease‚Äù)\nPositive vs Negative net percentages (color coded as Yellow or Dark Blue)\n\n\nNow that you‚Äôre versed in the grammar of graphics (ggplot), list the aesthetics used and which variables are specified for each.\n\n\nx is mapped to net percentage of the population in the global region that believes that jobs will increase in the next five years due to technology\ny is mapped to the global region\nfill is mapped to whether the net percentage is positive or negative\n\n\nWhat type of graph would you call this?\n\nI wold call this a horizontal bar chart. I would use geom_bar() to create this plot.\n\nList all of the problems or things you would improve about this graph.\n\nThis plot is already pretty reader friendly. And I will be turning it into a map. But if I were to keep it as a bar chart, the details I would change include:\n\nColorizing the description so that ‚ÄúIncrease‚Äù is Yellow and ‚ÄúDecrease‚Äù is Dark Blue.\nI would remove the percentage markers at the end of each bar and make the bars hoverable so there are fewer numbers on the page.\nI would make the ‚ÄúWorld‚Äù bar a different color and more prominent. I actually missed that detail the first time I looked at it.\nI would include fewer x-axis labels. Every unit of 5 does not need to be included if the bars are hoverable\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\n\nAgreement vs Disagreement that Technology Will Increase the Number of Jobs in My Country in the Next Five Years\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(leaflet)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(sf)\nlibrary(htmltools)\n\n\n# Pull just Q19 responses\nq19_overall &lt;- wgm_clean %&gt;%\n  filter(Question == \"Q19 Overall, do you think that science and technology will increase or decrease the number of jobs in your local area in the next five years?\") %&gt;%\n  select(Country, Response, OverallPercent = `Column N %...4`) %&gt;%\n  distinct() %&gt;%\n  pivot_wider(names_from = Response, values_from = OverallPercent)\n\n\n# Clean summary table\nq19_final &lt;- q19_overall %&gt;%\n  select(Country, Increase, Decrease) %&gt;%\n  mutate(Total = Increase - Decrease)\n\n\n# Get country centroids\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\") %&gt;%\n  st_centroid()\n\n\ncentroids &lt;- world %&gt;%\n  select(Country = name_long, geometry) %&gt;%\n  st_coordinates() %&gt;%\n  as.data.frame() %&gt;%\n  bind_cols(Country = world$name_long)\n\n\n# Join coordinates to data\nq19_geo &lt;- q19_final %&gt;%\n  left_join(centroids, by = \"Country\") %&gt;%\n  filter(!is.na(X) & !is.na(Y))\n\n\n# Create diverging palette\nmax_val &lt;- max(abs(q19_geo$Total))\ndiverging_palette &lt;- colorNumeric(\n  palette = colorRampPalette(c(\"#440154\", \"#C7E9B4\", \"#5DC863\"))(100),\n  domain = c(-max_val * 0.5, max_val)\n)\n\n\n# Leaflet map (no search bar)\nleaflet(q19_geo) %&gt;%\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  addCircleMarkers(\n    lng = ~X,\n    lat = ~Y,\n    radius = 7,\n    color = ~diverging_palette(Total),\n    stroke = TRUE,\n    weight = 1,\n    opacity = 1,\n    fillOpacity = 0.9,\n    label = ~Country,\n    popup = ~paste0(\n      \"&lt;strong&gt;\", Country, \"&lt;/strong&gt;&lt;br&gt;\",\n      \"Net Agreement: \", round(Total * 100, 1), \"%\"\n    )\n  ) %&gt;%\n  addLegend(\n    \"bottomright\",\n    pal = diverging_palette,\n    values = ~Total,\n    title = \"Net % Agreement\",\n    labFormat = labelFormat(suffix = \"%\", transform = function(x) 100 * x),\n    opacity = 1\n  )"
  },
  {
    "objectID": "posts/2025-05-05-advanced-visualizations/index.html#third-data-visualization-improvement",
    "href": "posts/2025-05-05-advanced-visualizations/index.html#third-data-visualization-improvement",
    "title": "Advanced visualizations",
    "section": "Third Data Visualization Improvement",
    "text": "Third Data Visualization Improvement\nFor this third plot, you must use one of the other ggplot2 extension packages mentioned this week (e.g., gganimate, plotly, patchwork, cowplot).\n\nSelect a data visualization in the report that you think could be improved. Be sure to cite both the page number and figure title. Do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\n\nOriginal image (Source: Wellcome Global Monitor, 2018, p.¬†98.)\n\n\n\nreligion_science_disagreement.jpg\n\n\nThis plot intends to show how people tend to resolve informational disputes between science and the beliefs of their religion. Respondents had the choice of selecting ‚Äúscience‚Äù, ‚Äúthe teachings of my religion‚Äù, or ‚Äúit depends‚Äù. Response rates are grouped by answer choice and also by geographical region.\n\nList the variables that appear to be displayed in this visualization.\n\nVariables include:\n\nPercentage of people who believe science, their religion, or ‚Äúit depends‚Äù when faced with an informational conflict between the two\nGlobal region\nColor-coded bars so that different responses can be easily distinguished (colored Yellow for ‚ÄúScience‚Äù, Dark Blue for ‚ÄúReligion‚Äù, and Light Blue for ‚ÄúIt depends‚Äù)\n\n\nNow that you‚Äôre versed in the grammar of graphics (ggplot), list the aesthetics used and which variables are specified for each.\n\n\nx is mapped to net percentage of the population in the global region that choose to believe either science, the teachings of their religion, or ‚Äúit depends‚Äù when there is disagreement between them\ny is mapped to the global region\nfill is mapped to the response type\n\n\nWhat type of graph would you call this?\n\nI would call this a horizontal grouped bar plot. I would use geom_bar() to create this plot, with position = \"dodge\".\n\nList all of the problems or things you would improve about this graph.\n\nThis plot is a little harder to look at than the previous one. Here are the changes I would make:\n\nI would make the bars hoverable so that I can get rid of the copious percentages at the end of every bar.\nI would eliminate the legend and code the colors into the title / subtitle\nI would simplify the title\nI would make the x-axis showing percentages for easy visual estimations, but I would have fewer grid lines\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better."
  },
  {
    "objectID": "posts/2025-05-05-advanced-visualizations/index.html#which-are-you-more-likely-to-believe-when-there-is-disagreement",
    "href": "posts/2025-05-05-advanced-visualizations/index.html#which-are-you-more-likely-to-believe-when-there-is-disagreement",
    "title": "Advanced visualizations",
    "section": "Which are you more likely to believe when there is disagreement?",
    "text": "Which are you more likely to believe when there is disagreement?\n\n\nCode\nlibrary(dplyr)\nlibrary(ggtext)\n\n\n# Step 1: Add region labels based on country names\nwgm_clean &lt;- wgm_clean %&gt;%\n  mutate(Region = case_when(\n    Country %in% c(\"Kenya\", \"Tanzania\", \"Uganda\", \"Ethiopia\", \"Rwanda\", \"Burundi\") ~ \"Eastern Africa\",\n    Country %in% c(\"Chad\", \"Cameroon\", \"Central African Republic\", \"Democratic Republic of the Congo\") ~ \"Central Africa\",\n    Country %in% c(\"Algeria\", \"Morocco\", \"Tunisia\", \"Libya\", \"Egypt\") ~ \"North Africa\",\n    Country %in% c(\"South Africa\", \"Namibia\", \"Botswana\", \"Zimbabwe\", \"Lesotho\") ~ \"Southern Africa\",\n    Country %in% c(\"Nigeria\", \"Ghana\", \"Senegal\", \"Ivory Coast\", \"Sierra Leone\") ~ \"Western Africa\",\n\n    Country %in% c(\"Mexico\", \"Guatemala\", \"Honduras\", \"Nicaragua\", \"Costa Rica\", \"Panama\") ~ \"Central America & Mexico\",\n    Country %in% c(\"United States\", \"Canada\") ~ \"Northern America\",\n    Country %in% c(\"Brazil\", \"Argentina\", \"Colombia\", \"Chile\", \"Peru\", \"Venezuela\") ~ \"South America\",\n\n    Country %in% c(\"Kazakhstan\", \"Uzbekistan\", \"Kyrgyzstan\", \"Turkmenistan\", \"Tajikistan\") ~ \"Central Asia\",\n    Country %in% c(\"China\", \"Japan\", \"South Korea\", \"Taiwan\", \"Mongolia\") ~ \"East Asia\",\n    Country %in% c(\"Indonesia\", \"Thailand\", \"Vietnam\", \"Malaysia\", \"Philippines\", \"Myanmar\") ~ \"Southeast Asia\",\n    Country %in% c(\"India\", \"Pakistan\", \"Bangladesh\", \"Nepal\", \"Sri Lanka\") ~ \"South Asia\",\n\n    Country %in% c(\"Iran\", \"Iraq\", \"Saudi Arabia\", \"Turkey\", \"Jordan\", \"Lebanon\", \"Israel\") ~ \"Middle East\",\n    Country %in% c(\"Russia\", \"Ukraine\", \"Poland\", \"Romania\", \"Bulgaria\", \"Hungary\") ~ \"Eastern Europe\",\n    Country %in% c(\"United Kingdom\", \"Ireland\", \"Sweden\", \"Norway\", \"Denmark\") ~ \"Northern Europe\",\n    Country %in% c(\"Italy\", \"Spain\", \"Greece\", \"Portugal\") ~ \"Southern Europe\",\n    Country %in% c(\"France\", \"Germany\", \"Netherlands\", \"Belgium\", \"Switzerland\", \"Austria\") ~ \"Western Europe\",\n\n    Country %in% c(\"Australia\", \"New Zealand\") ~ \"Australia & New Zealand\",\n    TRUE ~ NA_character_\n  )\n)\n\n\n# Build region summary with only three meaningful responses\nq30_region_summary &lt;- wgm_clean %&gt;%\n  filter(Question == \"Q30 (If respondent believes science has disagreed with teachings of religion) Generally speaking, when science disagrees with the teachings of your religion, what do you believe? Science or the teachings of your religion?\") %&gt;%\n  filter(Response %in% c(\"Science\",\n                         \"The teachings of your religion\",\n                         \"(It depends)\")) %&gt;%\n  filter(!is.na(Region)) %&gt;%\n  group_by(Region, Response) %&gt;%\n  summarise(n = sum(`Unweighted Count...5`, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  group_by(Region) %&gt;%\n  mutate(Percent = n / sum(n) * 100) %&gt;%\n  ungroup()\n\n\n# ‚úÖ Recode labels to match fill colors\nq30_region_summary &lt;- q30_region_summary %&gt;%\n  mutate(Response = recode(Response,\n    \"The teachings of your religion\" = \"Religion\",\n    \"(It depends)\" = \"It depends\"\n  )\n)\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggtext)\nlibrary(plotly)\n\n\n# ggplot object with tooltip and custom styling\nq30_hover_plot &lt;- ggplot(q30_region_summary, aes(\n  x = Region,\n  y = Percent,\n  fill = Response,\n  text = paste0(Response, \": \", round(Percent, 1), \"%\")\n  )\n) +\n  geom_col(position = \"dodge\", width = 0.75) +\n  scale_y_continuous(\n    breaks = seq(0, 75, by = 12.5),\n    labels = function(x) {\n      ifelse(x %in% c(25, 50, 75), paste0(x, \"%\"), \"\")\n    }\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Science\" = \"#FFD700\",\n      \"It depends\" = \"#00BFFF\",\n      \"Religion\" = \"#002147\"\n    )\n  ) +\n  labs(\n    title = NULL,        \n    subtitle = NULL,\n    x = NULL,\n    y = NULL,\n    fill = NULL\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.y = element_text(size = 9),\n    axis.text.x = element_text(size = 9),\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\", size = 12),\n    plot.subtitle = element_markdown(size = 10),\n    plot.title.position = \"plot\",\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank()\n  ) +\n  coord_flip()\n\n\n# Convert to interactive plot with custom title + subtitle\nggplotly(q30_hover_plot, tooltip = \"text\") %&gt;%\n  layout(\n    margin = list(l = 0, r = 10, t = 130, b = 50),\n    title = list(\n      text = paste0(\n        \"&lt;span style='font-size:18px'&gt;&lt;b&gt;Which Are You More Likely to Believe When There is Disagreement?&lt;/b&gt;&lt;/span&gt;&lt;br&gt;\",\n        \"&lt;span style='font-size:14px'&gt;\",\n        \"&lt;span style='color:#FFD700'&gt;&lt;b&gt;Science&lt;/b&gt;&lt;/span&gt;, \",\n        \"the &lt;span style='color:#002147'&gt;&lt;b&gt;Teachings of Your Religion&lt;/b&gt;&lt;/span&gt;, or \",\n        \"&lt;span style='color:#00BFFF'&gt;&lt;b&gt;It Depends&lt;/b&gt;&lt;/span&gt;\",\n        \"&lt;/span&gt;\"\n      ),\n      x = 0,\n      xanchor = \"left\",\n      yanchor = \"top\"\n    )\n  )"
  },
  {
    "objectID": "posts/2025-06-07-writing-efficient-functions/index.html",
    "href": "posts/2025-06-07-writing-efficient-functions/index.html",
    "title": "Writing Efficient Functions",
    "section": "",
    "text": "This assignment will challenge your function writing abilities. I‚Äôm not going to lie, these functions are difficult but well within your reach. I do, however, want to recognize that not everyone is interested in being a ‚Äúvirtuoso‚Äù with their function writing. So, there are two options for this week‚Äôs lab:"
  },
  {
    "objectID": "posts/2025-06-07-writing-efficient-functions/index.html#testing-your-function",
    "href": "posts/2025-06-07-writing-efficient-functions/index.html#testing-your-function",
    "title": "Writing Efficient Functions",
    "section": "Testing Your Function!",
    "text": "Testing Your Function!\n\n\nCode\n## Testing how your function handles multiple input variables\nremove_outliers(diamonds, \n                price, \n                x, \n                y, \n                z)\n\n\n# A tibble: 52,689 √ó 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ‚Ñπ 52,679 more rows\n\n\nCode\n## Testing how your function handles an input that isn't numeric\nremove_outliers(diamonds, \n                price, \n                color)\n\n\nError in remove_outliers(diamonds, price, color): All selected variables must be numeric.\n\n\nCode\n## Testing how your function handles a non-default sd_thresh\nremove_outliers(diamonds, \n                price,\n                x, \n                y, \n                z, \n                sd_thresh = 2)\n\n\n# A tibble: 50,099 √ó 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ‚Ñπ 50,089 more rows\n\n\nExercise 2: Write a function that imputes missing values for numeric variables in a dataset. The user should be able to supply the dataset, the variables to impute values for, and a function to use when imputing. Hint 1: You will need to use across() to apply your function, since the user can input multiple variables. Hint 2: The replace_na() function is helpful here!\n\n\nCode\nlibrary(nycflights13)\n\nimpute_missing &lt;- function(df, ..., impute_fun = mean) {\n  # Capture the selected variables\n  vars &lt;- rlang::enquos(...)\n  \n  # Check all selected variables are numeric\n  all_numeric &lt;- purrr::map_lgl(vars, ~ is.numeric(dplyr::pull(df, !!.x)))\n  if (!all(all_numeric)) {\n    stop(\"All selected variables must be numeric.\")\n  }\n\ndf %&gt;%\n  mutate(across(\n    all_of(tidyselect::vars_select(names(df), !!!vars)),\n    ~ replace_na(.x, impute_fun(.x, na.rm = TRUE))\n  ))\n\n}"
  },
  {
    "objectID": "posts/2025-06-07-writing-efficient-functions/index.html#testing-your-function-1",
    "href": "posts/2025-06-07-writing-efficient-functions/index.html#testing-your-function-1",
    "title": "Writing Efficient Functions",
    "section": "Testing Your Function!",
    "text": "Testing Your Function!\n\n\nCode\n## Testing how your function handles multiple input variables\nimpute_missing(nycflights13::flights, \n               arr_delay, \n               dep_delay) \n\n\n# A tibble: 336,776 √ó 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ‚Ñπ 336,766 more rows\n# ‚Ñπ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nCode\n# Testing that there are no NAs in the imputed dataset\n\nflights_clean &lt;- impute_missing(nycflights13::flights, arr_delay, dep_delay)\n\n# Check for remaining NAs\nflights_clean %&gt;%\n  summarize(\n    arr_delay_missing = sum(is.na(arr_delay)),\n    dep_delay_missing = sum(is.na(dep_delay))\n  )\n\n\n# A tibble: 1 √ó 2\n  arr_delay_missing dep_delay_missing\n              &lt;int&gt;             &lt;int&gt;\n1                 0                 0\n\n\nCode\n## Testing how your function handles an input that isn't numeric\nimpute_missing(nycflights13::flights, \n               arr_delay, \n               carrier)\n\n\nError in impute_missing(nycflights13::flights, arr_delay, carrier): All selected variables must be numeric.\n\n\nCode\n## Testing how your function handles a non-default impute_fun\nimpute_missing(nycflights13::flights, \n               arr_delay, \n               dep_delay, \n               impute_fun = median)\n\n\n# A tibble: 336,776 √ó 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ‚Ñπ 336,766 more rows\n# ‚Ñπ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nCode\n# Checking to see if means and medians return different datasets\nflights_mean &lt;- impute_missing(nycflights13::flights, arr_delay, dep_delay)\nflights_median &lt;- impute_missing(nycflights13::flights, arr_delay, dep_delay, impute_fun = median)\n\nall.equal(flights_mean, flights_median)\n\n\n[1] \"Component \\\"dep_delay\\\": Mean relative difference: 1.158239\"\n[2] \"Component \\\"arr_delay\\\": Mean relative difference: 1.725124\""
  },
  {
    "objectID": "posts/2025-06-07-writing-efficient-functions/index.html#testing-your-function-2",
    "href": "posts/2025-06-07-writing-efficient-functions/index.html#testing-your-function-2",
    "title": "Writing Efficient Functions",
    "section": "Testing Your Function!",
    "text": "Testing Your Function!\n\n\nCode\nfit_model(\n  diamonds,\n  mod_formula = price ~ carat + cut,\n  remove_outliers = TRUE,\n  impute_missing = TRUE,\n  price, \n  carat\n)\n\n\n\nCall:\nlm(formula = mod_formula, data = df)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2701.38      7871.08      1239.80      -528.60       367.91        74.59"
  },
  {
    "objectID": "posts/2025-06-07-writing-efficient-functions/index.html#parameters",
    "href": "posts/2025-06-07-writing-efficient-functions/index.html#parameters",
    "title": "Writing Efficient Functions",
    "section": "Parameters",
    "text": "Parameters\nFirst, we need to define the set of parameters we want to iterate the fit_model() function over. The tidyr package has a useful function called crossing() that is useful for generating argument combinations. For each argument, we specify all possible values for that argument and crossing() generates all combinations. Note that you can create a list of formula objects in R with c(y ~ x1, y ~ x1 + x2).\n\n\nCode\ndf_arg_combos &lt;- crossing(\n    impute = c(TRUE, FALSE),\n    remove_outliers = c(TRUE, FALSE), \n    mod = c(y ~ x1, \n            y ~ x1 + x2)\n)\ndf_arg_combos\n\n\nExercise 4: Use crossing() to create the data frame of argument combinations for our analyses.\n\n\nCode\nformulas &lt;- list(\n  price ~ carat,\n  price ~ carat + cut,\n  price ~ carat + cut + clarity,\n  price ~ carat + cut + clarity + color\n)\n\ndf_arg_combos &lt;- tidyr::crossing(\n  impute = c(TRUE, FALSE),\n  remove_outliers = c(TRUE, FALSE),\n  mod_formula = formulas\n)\n\ndf_arg_combos\n\n\n# A tibble: 16 √ó 3\n   impute remove_outliers mod_formula\n   &lt;lgl&gt;  &lt;lgl&gt;           &lt;list&gt;     \n 1 FALSE  FALSE           &lt;formula&gt;  \n 2 FALSE  FALSE           &lt;formula&gt;  \n 3 FALSE  FALSE           &lt;formula&gt;  \n 4 FALSE  FALSE           &lt;formula&gt;  \n 5 FALSE  TRUE            &lt;formula&gt;  \n 6 FALSE  TRUE            &lt;formula&gt;  \n 7 FALSE  TRUE            &lt;formula&gt;  \n 8 FALSE  TRUE            &lt;formula&gt;  \n 9 TRUE   FALSE           &lt;formula&gt;  \n10 TRUE   FALSE           &lt;formula&gt;  \n11 TRUE   FALSE           &lt;formula&gt;  \n12 TRUE   FALSE           &lt;formula&gt;  \n13 TRUE   TRUE            &lt;formula&gt;  \n14 TRUE   TRUE            &lt;formula&gt;  \n15 TRUE   TRUE            &lt;formula&gt;  \n16 TRUE   TRUE            &lt;formula&gt;"
  },
  {
    "objectID": "posts/2025-06-07-writing-efficient-functions/index.html#iterating-over-the-parameters",
    "href": "posts/2025-06-07-writing-efficient-functions/index.html#iterating-over-the-parameters",
    "title": "Writing Efficient Functions",
    "section": "Iterating Over the Parameters",
    "text": "Iterating Over the Parameters\nWe‚Äôve arrived at the final step!\nExercise 5: Use pmap() from purrr to apply the fit_model() function to every combination of arguments from `diamonds.\n\n\nCode\nlibrary(purrr)\n\nmodel_results &lt;- df_arg_combos %&gt;%\n  mutate(model = pmap(\n    list(impute, remove_outliers, mod_formula),\n    function(impute, remove_outliers, mod_formula) {\n      fit_model(\n        df = diamonds,\n        mod_formula = mod_formula,\n        impute_missing = impute,\n        remove_outliers = remove_outliers,\n        # vars for cleaning:\n        price, carat\n      )\n    }\n  ))\n\nprint(model_results, n = 50)\n\n\n# A tibble: 16 √ó 4\n   impute remove_outliers mod_formula model \n   &lt;lgl&gt;  &lt;lgl&gt;           &lt;list&gt;      &lt;list&gt;\n 1 FALSE  FALSE           &lt;formula&gt;   &lt;lm&gt;  \n 2 FALSE  FALSE           &lt;formula&gt;   &lt;lm&gt;  \n 3 FALSE  FALSE           &lt;formula&gt;   &lt;lm&gt;  \n 4 FALSE  FALSE           &lt;formula&gt;   &lt;lm&gt;  \n 5 FALSE  TRUE            &lt;formula&gt;   &lt;lm&gt;  \n 6 FALSE  TRUE            &lt;formula&gt;   &lt;lm&gt;  \n 7 FALSE  TRUE            &lt;formula&gt;   &lt;lm&gt;  \n 8 FALSE  TRUE            &lt;formula&gt;   &lt;lm&gt;  \n 9 TRUE   FALSE           &lt;formula&gt;   &lt;lm&gt;  \n10 TRUE   FALSE           &lt;formula&gt;   &lt;lm&gt;  \n11 TRUE   FALSE           &lt;formula&gt;   &lt;lm&gt;  \n12 TRUE   FALSE           &lt;formula&gt;   &lt;lm&gt;  \n13 TRUE   TRUE            &lt;formula&gt;   &lt;lm&gt;  \n14 TRUE   TRUE            &lt;formula&gt;   &lt;lm&gt;  \n15 TRUE   TRUE            &lt;formula&gt;   &lt;lm&gt;  \n16 TRUE   TRUE            &lt;formula&gt;   &lt;lm&gt;"
  },
  {
    "objectID": "posts/2025-06-07-webscraping/index.html",
    "href": "posts/2025-06-07-webscraping/index.html",
    "title": "Web Scraping",
    "section": "",
    "text": "Goal: Scrape information from https://www.cheese.com to obtain a dataset of characteristics about different cheeses, and gain deeper insight into your coding process. ü™§\n\nPart 1: Locate and examine the robots.txt file for this website. Summarize what you learn from it.\nThe robots.txt file only had two lines. It read: User-agent: * Sitemap: https://www.cheese.com/sitemap.xml. This means that is has no restrictions. Presumably this is because it is a relatively low-traffic website.\nPart 2: Learn about the html_attr() function from rvest. Describe how this function works with a small example.\nThis function gets the attributes associated with some HTML elements.\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\n\nread_html(\"https://www.cheese.com/alphabetical/?per_page=100\") |&gt;\n  html_nodes(\".product-img a img\") |&gt;\n  html_attr(\"class\")\n\n\n  [1] \"image-exists\"  \"image-missing\" \"image-exists\"  \"image-exists\" \n  [5] \"image-exists\"  \"image-exists\"  \"image-missing\" \"image-exists\" \n  [9] \"image-exists\"  \"image-exists\"  \"image-exists\"  \"image-missing\"\n [13] \"image-missing\" \"image-exists\"  \"image-missing\" \"image-missing\"\n [17] \"image-exists\"  \"image-missing\" \"image-exists\"  \"image-missing\"\n [21] \"image-missing\" \"image-missing\" \"image-missing\" \"image-exists\" \n [25] \"image-exists\"  \"image-exists\"  \"image-missing\" \"image-missing\"\n [29] \"image-missing\" \"image-missing\" \"image-missing\" \"image-missing\"\n [33] \"image-exists\"  \"image-missing\" \"image-missing\" \"image-exists\" \n [37] \"image-missing\" \"image-missing\" \"image-missing\" \"image-exists\" \n [41] \"image-exists\"  \"image-exists\"  \"image-exists\"  \"image-exists\" \n [45] \"image-exists\"  \"image-exists\"  \"image-exists\"  \"image-missing\"\n [49] \"image-missing\" \"image-missing\" \"image-missing\" \"image-missing\"\n [53] \"image-missing\" \"image-missing\" \"image-missing\" \"image-exists\" \n [57] \"image-missing\" \"image-missing\" \"image-exists\"  \"image-missing\"\n [61] \"image-missing\" \"image-missing\" \"image-missing\" \"image-missing\"\n [65] \"image-exists\"  \"image-missing\" \"image-exists\"  \"image-exists\" \n [69] \"image-missing\" \"image-missing\" \"image-missing\" \"image-exists\" \n [73] \"image-missing\" \"image-missing\" \"image-missing\" \"image-exists\" \n [77] \"image-exists\"  \"image-exists\"  \"image-missing\" \"image-missing\"\n [81] \"image-exists\"  \"image-exists\"  \"image-missing\" \"image-missing\"\n [85] \"image-exists\"  \"image-exists\"  \"image-missing\" \"image-missing\"\n [89] \"image-exists\"  \"image-missing\" \"image-missing\" \"image-exists\" \n [93] \"image-exists\"  \"image-missing\" \"image-missing\" \"image-missing\"\n [97] \"image-exists\"  \"image-missing\" \"image-missing\" \"image-missing\"\n\n\nThis small example demonstrates how to get whether the image exists for each cheese.\nPart 3: (Do this alongside Part 4 below.) I used ChatGPT to start the process of scraping cheese information with the following prompt:\n\nWrite R code using the rvest package that allows me to scrape cheese information from cheese.com.\n\nFully document your process of checking this code. Record any observations you make about where ChatGPT is useful / not useful.\n\n\nCode\n# Load required libraries\nlibrary(rvest)\nlibrary(dplyr)\n\n# Define the URL\nurl &lt;- \"https://www.cheese.com/alphabetical\"\n\n# Read the HTML content from the webpage\nwebpage &lt;- read_html(url)\n\n# Extract the cheese names and URLs\ncheese_data &lt;- webpage %&gt;%\n  html_nodes(\".cheese-item\") %&gt;%\n  html_nodes(\"a\") %&gt;%\n  html_attr(\"href\") %&gt;%\n  paste0(\"https://cheese.com\", .)\n\ncheese_names &lt;- webpage %&gt;%\n  html_nodes(\".cheese-item h3\") %&gt;%\n  html_text()\n\n# Create a data frame to store the results\ncheese_df &lt;- data.frame(\n  Name = cheese_names,\n  URL = cheese_data,\n  stringsAsFactors = FALSE\n)\n\n# Print the data frame\nprint(cheese_df)\n\n\nThe structure is nominally useful though the LLM appears to be guessing and can‚Äôt access the page structure.\nThe code is easy to read and is transparent for a reader to understand, but it isn‚Äôt very efficient. The verboseness is communicative, though ultimately unnecessary.\nPart 4: Obtain the following information for all cheeses in the database:\n\ncheese name\nURL for the cheese‚Äôs webpage (e.g., https://www.cheese.com/gouda/)\nwhether or not the cheese has a picture (e.g., gouda has a picture, but bianco does not).\n\nTo be kind to the website owners, please add a 1 second pause between page queries. (Note that you can view 100 cheeses at a time.)\n\n\nCode\nparse_page &lt;- function(url, delay = 1) {\n  Sys.sleep(delay)\n\n  # cheese product listings\n  cheeses &lt;- read_html(url) |&gt;\n    html_nodes(\".product-item\")\n\n  # temp object that's used twice\n  nodes &lt;- cheeses |&gt;\n    html_nodes(\"h3 a\")\n\n  # building tibble\n  tibble(\n    name = nodes |&gt; html_text(),\n    url = nodes |&gt;\n      html_attr(\"href\") |&gt;\n      (\\(slug) glue::glue(\"https://www.cheese.com{slug}\"))(),\n    has_image = cheeses |&gt;\n      html_nodes(\".product-img a img\") |&gt;\n      html_attr(\"class\") |&gt;\n      str_detect(\"image-exists\")\n  )\n}\n\n\n\n\nCode\n# can't run this on last page--will find number of pages to parse automatically.\nnum_pages &lt;- \"https://www.cheese.com/alphabetical/?per_page=100\" |&gt;\n  read_html() |&gt;\n  html_nodes(\".pagination a\") |&gt;\n  html_text() |&gt;\n  last() |&gt;\n  as.numeric()\n\ncheeses &lt;- paste0(\n  \"https://www.cheese.com/alphabetical/?per_page=100&page=\",\n  1:num_pages\n) |&gt;\n  map_df(parse_page)\n\n\nPart 5: When you go to a particular cheese‚Äôs page (like gouda), you‚Äôll see more detailed information about the cheese. For just 10 of the cheeses in the database, obtain the following detailed information:\n\nmilk information\ncountry of origin\nfamily\ntype\nflavour\n\n(Just 10 to avoid overtaxing the website! Continue adding a 1 second pause between page queries.)\n\n\nCode\ncheese_list &lt;- c(\n  \"https://www.cheese.com/paneer/\",\n  \"https://www.cheese.com/chevre-en-marinade/\",\n  \"https://www.cheese.com/chevre-log/\",\n  \"https://www.cheese.com/goat-gouda/\",\n  \"https://www.cheese.com/gotcha-gouda/\",\n  \"https://www.cheese.com/gouda/\",\n  \"https://www.cheese.com/camembert-des-camarades/\",\n  \"https://www.cheese.com/camembert-de-portneuf/\",\n  \"https://www.cheese.com/camembert-de-normandie/\",\n  \"https://www.cheese.com/camembert/\"\n)\n\n\n\n\nCode\nparse_cheese &lt;- function(url, delay = 1) {\n}\n\n\"https://www.cheese.com/camembert-de-normandie/\" |&gt;\n  read_html() |&gt;\n  html_nodes(\".panel-body ul li\") |&gt;\n  html_text(trim = TRUE)\n# sep wider into tibble with NAs and rowbind or use hashmap or something?\n\n\n\n\nCode\nparse_cheese &lt;- function(url, delay = 1) {\n  Sys.sleep(delay)\n  \n  # Read page\n  page &lt;- read_html(url)\n  \n  # Extract bullet point text\n  raw_info &lt;- page %&gt;%\n    html_nodes(\".panel-body ul li\") %&gt;%\n    html_text(trim = TRUE)\n  \n  # Extract milk line separately (doesn't contain \":\")\n  milk_line &lt;- raw_info[grepl(\"^Made from\", raw_info)]\n  milk &lt;- str_remove(milk_line, \"^Made from \")\n\n  # Extract remaining fields that use a colon\n  info_pairs &lt;- raw_info[grepl(\":\", raw_info)] %&gt;%\n    str_split_fixed(\":\", 2) %&gt;%\n    as_tibble() %&gt;%\n    rename(field = V1, value = V2) %&gt;%\n    mutate(\n      field = str_trim(tolower(field)),\n      value = str_trim(value)\n    ) %&gt;%\n    filter(field %in% c(\"country of origin\", \"family\", \"type\", \"flavour\"))\n  \n  # Convert to wide format\n  cheese_info &lt;- pivot_wider(info_pairs, names_from = field, values_from = value)\n  \n  # Add milk column\n  cheese_info &lt;- cheese_info %&gt;%\n    mutate(milk = milk) %&gt;%\n    relocate(milk)\n\n  return(cheese_info)\n}\n\n\ncheese_details &lt;- map_dfr(cheese_list, parse_cheese)\n\n\n\n\nCode\n# Nice kable table\n\nlibrary(knitr)\nlibrary(kableExtra)\n\ncheese_details %&gt;%\n  rename(\n    Milk    = milk,\n    Country = `country of origin`,\n    Family  = family,\n    Type    = type,\n    Flavour = flavour\n  ) %&gt;%\n  kable(\n    caption = \"10 Cheeses\",\n    format = \"html\",\n    escape = TRUE\n  ) %&gt;%\n  kable_styling(\n    full_width = FALSE,\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n    position = \"left\"\n  )\n\n\n\n10 Cheeses\n\n\nMilk\nCountry\nFamily\nType\nFlavour\n\n\n\n\npasteurized cow's or water buffalo's milk\nBangladesh and India\nCottage\nfresh firm\nmilky\n\n\npasteurized goat's milk\nUnited States\nNA\nsemi-soft, artisan\ngarlicky, herbaceous, spicy\n\n\npasteurized goat's milk\nFrance\nNA\nfresh soft\ncitrusy\n\n\npasteurized goat's milk\nNetherlands\nGouda\nsemi-hard, artisan\ntangy\n\n\ncow's milk\nUnited States\nGouda\nsemi-hard, artisan\nsweet, tangy\n\n\npasteurized or unpasteurized cow's, goat's or sheep's milk\nNetherlands\nGouda\nhard\nfull-flavored\n\n\npasteurized cow's milk\nCanada\nCamembert\nsoft, soft-ripened\nbuttery, nutty, subtle, sweet\n\n\npasteurized cow's milk\nCanada\nCamembert\nsoft, soft-ripened\nbuttery, creamy\n\n\nunpasteurized cow's milk\nFrance\nCamembert\nsoft, soft-ripened\ncreamy\n\n\ncow's milk\nFrance\nCamembert\nsoft, artisan\nsweet\n\n\n\n\n\nPart 6: Evaluate the code that you wrote in terms of efficiency. To what extent do your function(s) adhere to the principles for writing good functions? To what extent are your functions efficient? To what extent is your iteration of these functions efficient?\nThe code is efficient. There are few objects saved and pipelines are used extensively to further that goal. Furthermore, leveraging Quarto‚Äôs design, we can further bolster efficiency by selectively caching the output of a few cells and make a nice space/time deal‚Äìscraping the data takes time due to the number of pages that need to be scraped, so we elected to cache those outputs. Of course, our code still has to run once, but since the targets seem to be static, this allows us to spend some memory to speed up execution time. Since we are caching, we save two objects so as to obviate scraping the site again."
  },
  {
    "objectID": "posts/2025-06-07-generative-art/index.html",
    "href": "posts/2025-06-07-generative-art/index.html",
    "title": "Generative Art",
    "section": "",
    "text": "To create this vortex, I wrote a function called make_petal() that places 150 petals in a circular pattern using trigonometry. I adjusted the inner and outer radius and the petal width, which allowed me to shape the form and density of the design. I used the ‚ÄúFantasticFox1‚Äù palette (I‚Äôm a big WA fan) and applied a mirrored gradient to give the piece a warm-to-cool symmetry. I also softened the borders with a faint black outline for a more smooth and delicate effect.\nThe animated version uses the same base pattern but rotates it over 500 frames, creating a slow, mesmerizing spin. I created the GIF using gifski_renderer() and embedded it into the document to keep the rendering process efficient.\n\n\nCode\nmake_petal &lt;- function(n_petals = 150,\n                       inner_radius = 1,\n                       outer_radius = 2.999,\n                       width = 0.1) {\n  \n  angles &lt;- seq(0, 2 * pi - (2 * pi / n_petals),\n                length.out = n_petals)\n\n  tibble(petal = 1:n_petals, angle = angles) %&gt;%\n    rowwise() %&gt;%\n    mutate(\n      x = list(c(\n        0,\n        inner_radius * cos(angle - width),\n        outer_radius * cos(angle),\n        inner_radius * cos(angle + width)\n      )),\n      y = list(c(\n        0,\n        inner_radius * sin(angle - width),\n        outer_radius * sin(angle),\n        inner_radius * sin(angle + width)\n      )),\n      id = petal\n    ) %&gt;%\n    unnest(c(x, y)) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n      gradient = abs(2 * (id - 1) / (n_petals - 1) - 1)\n    )\n}\n\n# Create data\ndf &lt;- make_petal(n_petals = 150)\n\n# Palette\nfox_colors &lt;- wes_palette(\"FantasticFox1\")\nmirror_palette &lt;- colorRampPalette(fox_colors)(100)\n\n# Plot with faint borders\nggplot(df, aes(x, y, group = id, fill = gradient)) +\n  geom_polygon(color = rgb(0, 0, 0, 0.05),\n               alpha = 0.95,\n               linejoin = \"mitre\",\n               size = 0.5) +\n  scale_fill_gradientn(colors = mirror_palette) +\n  coord_equal() +\n  theme_void() +\n  guides(fill = \"none\") +\n  ggtitle(\"1. Spectral Event Horizon [Static]\") +\n  theme(plot.title = element_text(size = 30,\n                                  hjust = 0.5,\n                                  face = \"bold\")\n        )\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(wesanderson)\nlibrary(gganimate)\nlibrary(gifski)\n\n# Petal data function with frame-based rotation\nmake_petal &lt;- function(n_petals = 150,\n                       frames = 60,\n                       inner_radius = 1,\n                       outer_radius = 2.999,\n                       width = 0.1) {\n  \n  angles &lt;- seq(0, 2 * pi - (2 * pi / n_petals), length.out = n_petals)\n \n  base &lt;- tibble(petal = 1:n_petals, angle = angles) %&gt;%\n    rowwise() %&gt;%\n    mutate(\n      x_base = list(c(\n        0,\n        inner_radius * cos(angle - width),\n        outer_radius * cos(angle),\n        inner_radius * cos(angle + width)\n      )),\n      y_base = list(c(\n        0,\n        inner_radius * sin(angle - width),\n        outer_radius * sin(angle),\n        inner_radius * sin(angle + width)\n      )),\n      id = petal\n    ) %&gt;%\n    unnest(c(x_base, y_base)) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n      gradient = abs(2 * (id - 1) / (n_petals - 1) - 1)\n    )\n\n  # Duplicate data across frames and rotate\n  expand_grid(base, frame = 1:frames) %&gt;%\n    mutate(\n      theta = 2 * pi * (frame - 1) / frames,  # rotation per frame\n      x = x_base * cos(theta) - y_base * sin(theta),\n      y = x_base * sin(theta) + y_base * cos(theta)\n    )\n}\n\ndf &lt;- make_petal(n_petals = 100, frames = 500)  # fewer petals + frames\n\np &lt;- ggplot(df, aes(x, y, group = interaction(id, frame), fill = gradient)) +\n  geom_polygon(color = rgb(0, 0, 0, 0.05),\n               alpha = 0.95,\n               size = 0.3,\n               linejoin = \"mitre\") +\n  scale_fill_gradientn(colors = mirror_palette) +\n  coord_equal() +\n  theme_void() +\n  guides(fill = \"none\") +\n  ggtitle(\"Spining\") +\n  transition_manual(frame)\n\nanimation &lt;- animate(\n  p,\n  fps = 25,\n  duration = 10,\n  width = 500,\n  height = 500,\n  res = 100,\n  renderer = gifski_renderer(),\n  verbose = TRUE\n)\nCode\nknitr::include_graphics(\"vortex_spin_final.gif\")\nCode\nlibrary(Rcpp)\nlibrary(ghibli)\n\n\nraster_art_circle &lt;- function(mat, palette, trim = 0.001, scale = 0.55) {\n  zlim &lt;- quantile(mat, c(trim, 1 - trim))\n  mat[mat &lt; zlim[1]] &lt;- zlim[1]\n  mat[mat &gt; zlim[2]] &lt;- zlim[2]\n\n  # Create circular mask\n  w &lt;- nrow(mat)\n  h &lt;- ncol(mat)\n  center_x &lt;- w / 2\n  center_y &lt;- h / 2\n  radius &lt;- min(center_x, center_y)\n\n  mask &lt;- outer(1:w, 1:h, function(i, j) {\n    (i - center_x)^2 + (j - center_y)^2 &lt;= radius^2\n  })\n\n  mat[!mask] &lt;- NA\n\n  op &lt;- par(mar = c(0, 0, 0, 0))\n  image(\n    z = mat,\n    axes = FALSE,\n    asp = 1,\n    useRaster = TRUE,\n    col = palette,\n    na.rm = TRUE\n  )\n  par(op)\n}\n\nlibrary(ghibli)\npalette &lt;- ghibli::ghibli_palette(\"MononokeMedium\", type = \"continuous\")\n\nRcpp::sourceCpp(\"unboxer_grid_circle.cpp\")\n\nset.seed(123)\nmat &lt;- unboxer_grid_circle_core(iterations = 1e7,\n                                layers = 10,\n                                pixels = 800,\n                                border = 1.2)\n\nraster_art_circle(mat, palette = palette)"
  },
  {
    "objectID": "posts/2025-06-07-generative-art/index.html#code-choices-exhibit-1",
    "href": "posts/2025-06-07-generative-art/index.html#code-choices-exhibit-1",
    "title": "Generative Art",
    "section": "",
    "text": "To create this vortex, I wrote a function called make_petal() that places 150 petals in a circular pattern using trigonometry. I adjusted the inner and outer radius and the petal width, which allowed me to shape the form and density of the design. I used the ‚ÄúFantasticFox1‚Äù palette (I‚Äôm a big WA fan) and applied a mirrored gradient to give the piece a warm-to-cool symmetry. I also softened the borders with a faint black outline for a more smooth and delicate effect.\nThe animated version uses the same base pattern but rotates it over 500 frames, creating a slow, mesmerizing spin. I created the GIF using gifski_renderer() and embedded it into the document to keep the rendering process efficient.\n\n\nCode\nmake_petal &lt;- function(n_petals = 150,\n                       inner_radius = 1,\n                       outer_radius = 2.999,\n                       width = 0.1) {\n  \n  angles &lt;- seq(0, 2 * pi - (2 * pi / n_petals),\n                length.out = n_petals)\n\n  tibble(petal = 1:n_petals, angle = angles) %&gt;%\n    rowwise() %&gt;%\n    mutate(\n      x = list(c(\n        0,\n        inner_radius * cos(angle - width),\n        outer_radius * cos(angle),\n        inner_radius * cos(angle + width)\n      )),\n      y = list(c(\n        0,\n        inner_radius * sin(angle - width),\n        outer_radius * sin(angle),\n        inner_radius * sin(angle + width)\n      )),\n      id = petal\n    ) %&gt;%\n    unnest(c(x, y)) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n      gradient = abs(2 * (id - 1) / (n_petals - 1) - 1)\n    )\n}\n\n# Create data\ndf &lt;- make_petal(n_petals = 150)\n\n# Palette\nfox_colors &lt;- wes_palette(\"FantasticFox1\")\nmirror_palette &lt;- colorRampPalette(fox_colors)(100)\n\n# Plot with faint borders\nggplot(df, aes(x, y, group = id, fill = gradient)) +\n  geom_polygon(color = rgb(0, 0, 0, 0.05),\n               alpha = 0.95,\n               linejoin = \"mitre\",\n               size = 0.5) +\n  scale_fill_gradientn(colors = mirror_palette) +\n  coord_equal() +\n  theme_void() +\n  guides(fill = \"none\") +\n  ggtitle(\"1. Spectral Event Horizon [Static]\") +\n  theme(plot.title = element_text(size = 30,\n                                  hjust = 0.5,\n                                  face = \"bold\")\n        )\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(wesanderson)\nlibrary(gganimate)\nlibrary(gifski)\n\n# Petal data function with frame-based rotation\nmake_petal &lt;- function(n_petals = 150,\n                       frames = 60,\n                       inner_radius = 1,\n                       outer_radius = 2.999,\n                       width = 0.1) {\n  \n  angles &lt;- seq(0, 2 * pi - (2 * pi / n_petals), length.out = n_petals)\n \n  base &lt;- tibble(petal = 1:n_petals, angle = angles) %&gt;%\n    rowwise() %&gt;%\n    mutate(\n      x_base = list(c(\n        0,\n        inner_radius * cos(angle - width),\n        outer_radius * cos(angle),\n        inner_radius * cos(angle + width)\n      )),\n      y_base = list(c(\n        0,\n        inner_radius * sin(angle - width),\n        outer_radius * sin(angle),\n        inner_radius * sin(angle + width)\n      )),\n      id = petal\n    ) %&gt;%\n    unnest(c(x_base, y_base)) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n      gradient = abs(2 * (id - 1) / (n_petals - 1) - 1)\n    )\n\n  # Duplicate data across frames and rotate\n  expand_grid(base, frame = 1:frames) %&gt;%\n    mutate(\n      theta = 2 * pi * (frame - 1) / frames,  # rotation per frame\n      x = x_base * cos(theta) - y_base * sin(theta),\n      y = x_base * sin(theta) + y_base * cos(theta)\n    )\n}\n\ndf &lt;- make_petal(n_petals = 100, frames = 500)  # fewer petals + frames\n\np &lt;- ggplot(df, aes(x, y, group = interaction(id, frame), fill = gradient)) +\n  geom_polygon(color = rgb(0, 0, 0, 0.05),\n               alpha = 0.95,\n               size = 0.3,\n               linejoin = \"mitre\") +\n  scale_fill_gradientn(colors = mirror_palette) +\n  coord_equal() +\n  theme_void() +\n  guides(fill = \"none\") +\n  ggtitle(\"Spining\") +\n  transition_manual(frame)\n\nanimation &lt;- animate(\n  p,\n  fps = 25,\n  duration = 10,\n  width = 500,\n  height = 500,\n  res = 100,\n  renderer = gifski_renderer(),\n  verbose = TRUE\n)"
  },
  {
    "objectID": "posts/2025-06-07-generative-art/index.html#code-choices-exhibit-2",
    "href": "posts/2025-06-07-generative-art/index.html#code-choices-exhibit-2",
    "title": "Generative Art",
    "section": "Code Choices (Exhibit 2)",
    "text": "Code Choices (Exhibit 2)\nFor this piece, I created a custom C++ function based on the one from the Iterated Function Systems tutorial. I called it unboxer_grid_circle(), which simulates iterative transformations in a confined space. This produced the below image, which I then masked into a perfect circle using a different function called raster_art_circle(). I adjusted the scale to control the proportion of the visible part, centering the image. I used the ‚ÄúMononokeMedium‚Äù palette (I‚Äôm also a big Ghibli fan) to create an earthy, mysterious mood."
  },
  {
    "objectID": "posts/2025-06-07-json-data-and-apis/index.html",
    "href": "posts/2025-06-07-json-data-and-apis/index.html",
    "title": "JSON Data and API‚Äôs",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(tidyjson)\nlibrary(lubridate)\n\nstates &lt;- read_table(\n  \"https://people.sc.fsu.edu/~jburkardt/datasets/states/state_capitals_ll.txt\",\n  col_names = c(\"state\", \"lat\", \"long\")\n) |&gt;\n  filter(state != \"US\")\n\nget_datetimes &lt;- function(lat, long, wait = 0.1) {\n  Sys.sleep(wait)\n\n  tryCatch(\n    {\n      start_times &lt;- httr::GET(\n        glue::glue(\n          \"https://api.g7vrd.co.uk/v1/satellite-passes/25544/{lat}/{long}.json\"\n        ),\n        httr::timeout(10)\n      )$content |&gt;\n        rawToChar() |&gt;\n        as.tbl_json() |&gt;\n        enter_object(\"passes\") |&gt;\n        gather_array() |&gt;\n        spread_all() |&gt;\n        mutate(start_dt = as_datetime(start)) |&gt;\n        filter(!is.na(start_dt)) |&gt;\n        arrange(start_dt) |&gt;\n        pull(start_dt)\n\n      valid_pass &lt;- \\(n)\n        if (length(start_times) &gt;= n) start_times[n] else NA_POSIXct_\n\n      tibble(\n        pass1 = valid_pass(1),\n        pass2 = valid_pass(2),\n        pass3 = valid_pass(3),\n      )\n    },\n    error = function(e) {\n      warning(glue::glue(\n        \"Error processing API for ({lat},{long}): {e$message}\"\n      ))\n      tibble(\n        pass1 = NA_POSIXct_,\n        pass2 = NA_POSIXct_,\n        pass3 = NA_POSIXct_\n      )\n    }\n  )\n}\n\nresult &lt;- bind_cols(states, map2_df(states$lat, states$long, get_datetimes)) |&gt;\n  write_csv(\"space_data.csv\")"
  },
  {
    "objectID": "posts/2025-06-07-json-data-and-apis/index.html#pass-times-for-u.s.-state-captials",
    "href": "posts/2025-06-07-json-data-and-apis/index.html#pass-times-for-u.s.-state-captials",
    "title": "JSON Data and API‚Äôs",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(tidyjson)\nlibrary(lubridate)\n\nstates &lt;- read_table(\n  \"https://people.sc.fsu.edu/~jburkardt/datasets/states/state_capitals_ll.txt\",\n  col_names = c(\"state\", \"lat\", \"long\")\n) |&gt;\n  filter(state != \"US\")\n\nget_datetimes &lt;- function(lat, long, wait = 0.1) {\n  Sys.sleep(wait)\n\n  tryCatch(\n    {\n      start_times &lt;- httr::GET(\n        glue::glue(\n          \"https://api.g7vrd.co.uk/v1/satellite-passes/25544/{lat}/{long}.json\"\n        ),\n        httr::timeout(10)\n      )$content |&gt;\n        rawToChar() |&gt;\n        as.tbl_json() |&gt;\n        enter_object(\"passes\") |&gt;\n        gather_array() |&gt;\n        spread_all() |&gt;\n        mutate(start_dt = as_datetime(start)) |&gt;\n        filter(!is.na(start_dt)) |&gt;\n        arrange(start_dt) |&gt;\n        pull(start_dt)\n\n      valid_pass &lt;- \\(n)\n        if (length(start_times) &gt;= n) start_times[n] else NA_POSIXct_\n\n      tibble(\n        pass1 = valid_pass(1),\n        pass2 = valid_pass(2),\n        pass3 = valid_pass(3),\n      )\n    },\n    error = function(e) {\n      warning(glue::glue(\n        \"Error processing API for ({lat},{long}): {e$message}\"\n      ))\n      tibble(\n        pass1 = NA_POSIXct_,\n        pass2 = NA_POSIXct_,\n        pass3 = NA_POSIXct_\n      )\n    }\n  )\n}\n\nresult &lt;- bind_cols(states, map2_df(states$lat, states$long, get_datetimes)) |&gt;\n  write_csv(\"space_data.csv\")"
  },
  {
    "objectID": "posts/2025-06-07-json-data-and-apis/index.html#mapping-the-data",
    "href": "posts/2025-06-07-json-data-and-apis/index.html#mapping-the-data",
    "title": "JSON Data and API‚Äôs",
    "section": "Mapping the Data",
    "text": "Mapping the Data\n\n\nCode\n# Load libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(lutz)\nlibrary(purrr)\nlibrary(leaflet)\n\n# Read in your ISS pass data CSV\nspace_data &lt;- read_csv(\"space_data.csv\")\n\n# Clean the data:\n#    - Remove rows where all passes are NA\n#    - Filter only valid U.S. longitudes (negative)\ncleaned_space &lt;- space_data %&gt;%\n  filter(!(is.na(pass1) & is.na(pass2) & is.na(pass3))) %&gt;%\n  filter(long &lt; 0)\n\n# Assign time zones based on latitude & longitude\ncleaned_space &lt;- cleaned_space %&gt;%\n  mutate(tz = tz_lookup_coords(lat, long, method = \"accurate\"))\n\n# Keep only rows with valid Olson time zones\ncleaned_space &lt;- cleaned_space %&gt;%\n  filter(tz %in% OlsonNames())\n\n# Convert UTC pass times to local time for each state (rowwise using map2)\ncleaned_space &lt;- cleaned_space %&gt;%\n  mutate(\n    pass1_local = as_datetime(unlist(map2(pass1, tz, ~ with_tz(.x, .y)))),\n    pass2_local = as_datetime(unlist(map2(pass2, tz, ~ with_tz(.x, .y)))),\n    pass3_local = as_datetime(unlist(map2(pass3, tz, ~ with_tz(.x, .y))))\n  )\n\n\nrocket_icon &lt;- makeIcon(\n  iconUrl = \"rocket.svg\",\n  iconWidth = 30, # Adjust size as needed\n  iconHeight = 30\n)"
  },
  {
    "objectID": "posts/2025-06-07-json-data-and-apis/index.html#international-space-station-pass-times-local-time-zones",
    "href": "posts/2025-06-07-json-data-and-apis/index.html#international-space-station-pass-times-local-time-zones",
    "title": "JSON Data and API‚Äôs",
    "section": "International Space Station Pass Times (Local Time Zones)",
    "text": "International Space Station Pass Times (Local Time Zones)\n\n\nCode\n# Plot\nm &lt;- leaflet(cleaned_space) %&gt;%\n  addTiles() %&gt;%\n  addMarkers(\n    lng = ~long,\n    lat = ~lat,\n    icon = rocket_icon,\n\n    # Hover label shows next pass in local time\n    label = ~ paste0(\"Next pass: \", format(pass1_local, \"%Y-%m-%d %H:%M:%S\")),\n\n    # Clickable popup shows all 3 local pass times\n    popup = ~ paste0(\n      \"&lt;b&gt;\",\n      state,\n      \"&lt;/b&gt;&lt;br/&gt;\",\n      \"Pass 1: \",\n      format(pass1_local, \"%Y-%m-%d %H:%M:%S\"),\n      \"&lt;br/&gt;\",\n      \"Pass 2: \",\n      format(pass2_local, \"%Y-%m-%d %H:%M:%S\"),\n      \"&lt;br/&gt;\",\n      \"Pass 3: \",\n      format(pass3_local, \"%Y-%m-%d %H:%M:%S\")\n    )\n  )\nm"
  },
  {
    "objectID": "posts/2025-06-07-json-data-and-apis/index.html#drawing-the-route-of-the-iss",
    "href": "posts/2025-06-07-json-data-and-apis/index.html#drawing-the-route-of-the-iss",
    "title": "JSON Data and API‚Äôs",
    "section": "Drawing the Route of the ISS",
    "text": "Drawing the Route of the ISS\n\n\nCode\nlibrary(leaflet.extras2)\n\nordered_result &lt;- result |&gt;\n  filter(!is.na(pass1)) |&gt;\n  arrange(pass1)\n\nm |&gt;\n  addArrowhead(\n    data = ordered_result,\n    lat = ~lat,\n    lng = ~long,\n    color = \"red\",\n    options = arrowheadOptions(\n      frequency = \"200px\",\n      size = \"10px\",\n      color = \"purple\",\n      opacity = 1,\n      fill = TRUE\n    )\n  )"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]