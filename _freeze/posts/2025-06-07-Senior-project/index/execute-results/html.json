{
  "hash": "7bfd49c2d0f8278910aaca15adb0ad69",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Meditation and retrospective time estimation\"\ndescription: An empirical study investigating the effect of mindfulness meditation on how we perceive the flow of time.\nauthor:\n  - Matt Babb\n  - J.P. Boiler\n  - James Elliott\n  - James Antony\ndate: 06-07-2025\ncategories: [Quarto, R, CSS, CSL]\nimage: lof_plot.jpg\nformat:\n  html:\n    css: styles.css\n    csl: apa.csl\n    bibliography: MTP_references.bib\neditor: source\nembed-resources: true\necho: true\nwarning: false\nerror: false\ncode-fold: true\ncode-tools: true\n---\n\n# Abstract\n> Retrospective time estimation is a key component of subjective time perception, yet it remains underexplored for longer durations (e.g., over five minutes). This study tested whether experimentally manipulating participants’ level of focus could influence retrospective time estimation. Participants (N = 99) listened to one of three different 13-minute, 13-second audio recordings: a mindfulness meditation, a short story, or silence (mind wandering condition). Afterward, they estimated how much time had passed, and then completed questionnaires measuring their perceived focus, subjective time passage, Big Five personality traits, mindful awareness, mental well-being, and sleepiness. **Results showed no significant effect of listening condition on retrospective time estimation, and none of the predictor variables reliably influenced retrospective time estimates**. Implications are considered in relation to the internal clock model and prior findings on time estimation for shorter durations.\n\n\n# Introduction\n\n**Subjective time perception (STP)** plays a central role in human cognition, with implications for both practical functioning and emotional experience. How individuals perceive time affects their ability to navigate fast-paced environments, to make effective decisions in both everyday and high-stakes contexts, and to reflect meaningfully on the past and future. A better understanding of how the mind tracks and subdivides time can inform cognitive and psychological research aimed at fostering safer, more efficient, and more fulfilling lives.\nHowever, despite a large body of work on time perception, relatively few studies have investigated retrospective time estimation for durations longer than a few minutes—a key gap in the literature. The present study addresses this gap by examining RTE for time intervals that approximate the typical length of commercially available guided mindfulness meditation sessions.\n\n### How STP Is Measured\n\nSTP can be divided into three distinct but interrelated domains:\n  \n  - **(1) temporal processing**\n  - **(2) time passage**\n  - **(3) duration perception**\n  \nEach of these has unique empirical correlates and can vary independently.\n\n**Temporal processing** refers to the ability to detect the simultaneity or sequence of stimuli. It is largely unconscious and closely tied to sensory systems such as vision and hearing. Research has shown that humans can consciously detect the order of visual stimuli with a resolution as fine as 20 milliseconds [@chassignolle2021], and auditory stimuli with a resolution of 2–3 milliseconds [@shinn2003].\n\n**Time passage** is the internal sense of how quickly time seems to move—a subjective feeling that time is “flying,” “dragging,” or even “standing still,” depending on one’s activity or mental state. This dimension of STP is more conscious than temporal processing and is often described using metaphorical language, which varies cross-culturally. For example, while Western cultures typically conceptualize time as moving from left to right, some Indigenous cultures represent time as moving front to back or along cardinal directions [@boroditsky2010].\n\n**Duration perception** involves the explicit estimation of elapsed time and relies heavily on cognitive mechanisms such as attention and memory. Researchers use several experimental paradigms to measure this domain, including:\n\n  - **Prospective time estimation**: Participants track time while knowing they will be asked to estimate it later (e.g., “Tell me when one minute has passed”).\n  - **Retrospective time estimation**: Participants estimate how much time has passed without having tracked it explicitly (e.g., “How long has it been since you began reading?”).\n  - **Time reproduction**: Participants are shown a stimulus for a given interval and asked to reproduce that interval using a signal.\n  - **Duration discrimination**: Participants compare two intervals and indicate which one felt longer.\n  \nThe present study focuses on the **time passage (TP)** and **retrospective time estimation (RTE)** domains. Specifically, it investigates whether experimentally induced differences in perceived **level of focus (LOF)** can reliably influence either of these two facets of STP.\n\n### The Internal Clock Model of STP\n\nOne of the most well-supported models of STP is the *internal clock model* [@droitvolet2007]. This model proposes that the brain contains a pacemaker-accumulator system that generates and stores neural pulses over time. These pulses are thought to accumulate in proportion to perceived duration: the more pulses collected, the longer the subjective estimate. Conversely, when attention is diverted away from time, fewer pulses are accumulated, resulting in shorter time estimates. Other factors, such as emotional arousal, can accelerate the pacemaker’s output, leading to distortions in perceived time. For example, in highly arousing or threatening situations, people often report that time seems to “slow down”—as during a car accident or other adrenaline-inducing event [@youvan2024].\n\nAt first glance, these results may seem to contradict a common experience: that “time flies” when people are deeply engaged in enjoyable or challenging tasks. If heightened engagement entails increased focus, why doesn’t time seem to slow down in such situations, resulting in longer estimations of time?\n\nSeveral refinements to the internal clock model address this apparent contradiction. One explanation is that subjective time lengthens only when attention is directed toward time itself, not simply when a person is focused. In fact, engaging tasks tend to draw attention away from time, effectively “closing” the gate of the accumulator, leading to fewer pulses being registered and a shorter perceived duration.\n\nAnother explanation emphasizes the difference between prospective and retrospective time judgments. In prospective tasks, participants know in advance that they will be asked to judge time, so attention plays a key role. In contrast, retrospective judgments rely more on memory, such as how many events were encoded or how novel the experience felt. Thus, a person may feel that time passed quickly after an engaging activity (due to limited memory encoding), even if time felt subjectively rich or long during the task itself.\n\n### Other Cognitive Factors That Influence STP\n\n#### **Focus**\n\nThere is substantial evidence that cognitive focus influences STP. According to @matthews2016, attention, memory, and sensory vividness shape perceived duration—novel or intense stimuli tend to lengthen perceived time, while familiarity and distraction shorten it.\n\nIn another study by @polti2018, participants completed time production tasks (30, 60, or 90 seconds) either alone or while performing an N-back task. They found that participants overestimated time in the no-distractor condition but underestimated time under cognitive load, with greater task difficulty producing greater underestimations.\n\nTo examine how bodily self-awareness influences STP, @wittmann2010 exposed participants to static, receding, or ‘looming’ visual stimuli while recording brain activity using fMRI. Looming stimuli were judged to last longer, an effect linked to increased activation in regions associated with self-awareness and threat detection.\n\n@droitvolet2019 compared participants who completed a guided mindfulness meditation with those who listened to poetry, then asked them to estimate the duration of auditory stimuli. Meditators underestimated short intervals but overestimated longer ones, consistent with a dual-process model where attention influences short durations via an internal clock, while memory dominates for longer durations.\n\n#### **Sleep**\n\nSleep deprivation appears to differentially affect types of STP. @sen2023 found that after 24 hours without sleep, participants exhibited longer RTE, while prospective time estimates remained largely unchanged—likely due to greater impairments in memory than in attention.\n\nHowever, this contrasts with a meta-analysis by @lim2010, which reported that attention (a lower-order function) is more susceptible to sleep deprivation than memory and reasoning (higher-order functions). This discrepancy raises questions about the reliability of subjective focus measures, which are explored further in the present study.\n\n#### **Mood**\n\nEmotional states can also significantly influence STP. In an experience-sampling study, @tipples2018 found that frustration was strongly associated with a sense that time was dragging, while happiness, physical activity, and future-oriented thoughts made time feel like it passed more quickly.\n\n@vanhedger2017 asked participants to reproduce the duration of emotionally valenced images before and after undergoing the Trier Social Stress Test (TSST). After the stress induction, participants overestimated the durations of both positive and negative stimuli, suggesting that acute stress can lengthen STP not only in the moment but also in its aftermath.\n\n#### **Personality**\n\nIn one study, @weibel2010 found that while Neuroticism, Extraversion, and Openness were all linked to a tendency to become immersed in emotionally engaging content, only Openness significantly predicted absorption—an experience often associated with time underestimation [@dalcin2020].\n\n@barhaim2010 examined trait anxiety and found that participants high in anxiety overestimated the duration of short (2-second) emotional face stimuli, particularly those that were threatening. This effect diminished at longer intervals, aligning with dual-process models of time perception that distinguish between clock-based and attention-based mechanisms across timescales.\n\n### Diverging Experiences of Time in Mindfulness Meditation\n\nA peculiar dichotomy of STP is often reported by experienced mindfulness practitioners. Some report that time seems to drag—sessions feel much longer than expected, especially when anticipating the end. Others report that time flies—sessions end more quickly than anticipated, often triggered by a bell or closing cue. Among meditators, these contrasting experiences are commonly attributed to the “quality” of the session: the degree of presence, depth of focus, and quietude of thought.\n\nIn terms of the internal clock model, a high-quality meditation session may involve minimal attention to time and fewer cognitively encoded events (e.g., discursive thoughts). This would lead to a reduced accumulation of internal pulses, resulting in shorter RTEs. Conversely, more distracted sessions may involve more fixation on the passage of time, and may produce more cognitive events and pulses, leading to longer RTEs.\nThese observations motivated a key exploratory goal of the present study: to examine whether meditation-induced variations in perceived focus are associated with RTE. This leads to the following hypotheses:\n\n\n### Hypotheses\n\n> **Hypothesis A:** Higher perceived level of focus (LOF) will predict shorter RTE across all experimental conditions.  \n>\n> **Hypothesis B:** Sleepiness will be associated with lower LOF, and therefore predict longer RTE across conditions.  \n>\n> **Hypothesis C:** Higher mindful awareness will be associated with higher LOF and, in turn, shorter RTE regardless of condition.\n\n<br>\n\n# Methods\n\n#### **Participants**\n\n\n\n99 undergraduate students (ages 18–23; 85 female, 14 male) from California Polytechnic State University, San Luis Obispo participated in the study. Participants were recruited through the Sona Systems Participant Management Pool from three psychology courses and received course credit as compensation. All participants complied with study procedures and completed all questionnaire items. The study received approval from the Cal Poly Institutional Review Board prior to data collection.\n\nParticipants reported diverse racial and ethnic identities. Of the 99 individuals, 16 identified as Asian, 29 as Latino, 69 as White, 4 as Middle Eastern, 2 as Black, 2 as Native Hawaiian, 1 as “Other,” and 1 selected “Prefer not to say.” Note that participants were able to select more than one category, so totals may exceed 99.\n\n#### **Design and Procedure**\n\nThis study employed a between-subjects design, with participants randomly assigned to one of three listening conditions: a guided mindfulness meditation (experimental condition), a short story (active control), or a mind-wandering prompt (passive control). All audio recordings were exactly 13 minutes and 13 seconds long and were delivered through standardized headphones at a consistent volume.\n\nAfter providing informed consent and receiving a brief overview of the procedure, participants relinquished all time-keeping devices and entered a quiet testing room. Each participant sat alone facing a blank wall to minimize distractions. They were instructed to listen to the assigned audio recording and notify the administrator once it ended. The administrator, stationed just outside the room, then guided the participant through the next phase of the study.\nFollowing the recording, participants completed a packet of seven pen-and-paper questionnaires presented in a standardized order. Upon completion, they were debriefed and received course credit electronically.\n\n### Materials\n\n*Click below to access the full dataset and materials:*\n\n<p>\n  <a href=\"https://drive.google.com/drive/folders/16QqxFMDxu2GOnWWRjAkBFmwNscFSrLiA?usp=drive_link\" target=\"_blank\" style=\"padding:8px 16px; background-color:#4B0082; color:white; font-size:0.9em; text-decoration:none; border-radius:4px;\">View Materials</a>\n</p>\n\n#### **Audio Recordings**\n\nThree audio recordings of equal length (13 minutes, 13 seconds) were used to elicit varying levels of attentional engagement:\n\n1. **Short story condition (SS)**: A narrative segment from *The Moth* featuring Jamie Johnson (grandson of the founder of Johnson & Johnson), in which he reflects on a documentary he was creating.\n\n2. **Mindfulness meditation condition (MM)**: A guided mindfulness session prompting participants to observe their breath, scan their body, and remain gently attentive to the present moment. The script included regular reminders to focus, relax, and respond non-judgmentally to distractions.\n\n3. **Mind wandering condition (MW)**: A stretch of silence following brief instructions encouraging participants to let their minds wander freely without doing anything in particular.\n\nAll recordings began with standardized instructions and ended with a spoken cue indicating that the session was complete.\n\n#### **Questionnaires**\n\nParticipants completed the following measures in the same sequence:\n\n1. **Time Estimation**\n\n   a. Participants wrote down, in minutes and seconds, how long they believed the audio recording lasted.\n   b. Time passage: Participants rated how quickly time seemed to pass during the recording on a 9-point Likert scale (1 = Very slowly, 9 = Very quickly).\n   \n   \n2. **Perceived Level of Focus (LOF)**\n\n   a. Rating: Participants indicated their attentional engagement on a 9-point Likert scale (1 = Very distracted / mind wandering, 9 = Very focused / engaged).\n   b. Elaboration: Participants described their mental and emotional state during the recording in an open-response section.\n   \n3. **Big Five Inventory (BFI-10)**: A brief personality measure assessing the Big Five traits using 10 items (2 per trait), rated from 1 (Disagree strongly) to 5 (Agree strongly).\n\n\n4. **Mindful Attention Awareness Scale (MAAS)**: A 15-item scale assessing trait mindfulness, rated from 1 (Almost always) to 6 (Almost never), with higher scores reflecting greater mindfulness.\n\n\n5. **Warwick-Edinburgh Mental Well-being Scale (WEMWBS)**: A 14-item scale assessing recent well-being, rated from 1 (None of the time) to 5 (All of the time), summed to produce a total well-being score.\n\n\n6. **Epworth Sleepiness Scale (ESS)**: An 8-item measure of daytime sleepiness, asking participants to rate their likelihood of dozing in various situations (0 = Would never nod off, 3 = High chance of dozing).\n\n\n7. **Demographics Questionnaire**: This included age, gender, race/ethnicity, education level, and brief questions about sleep, psychiatric history, medications, English fluency, and sensory impairments.\n\n<br>\n\n# Analysis\n\nThe primary objectives of the analysis were to evaluate the following hypotheses:\n\n> **Hypothesis A:** Higher perceived level of focus (LOF) will predict shorter RTE across all experimental conditions.  \n>\n> **Hypothesis B:** Sleepiness will be associated with lower LOF, and therefore predict longer RTE across conditions.  \n>\n> **Hypothesis C:** Higher mindful awareness will be associated with higher LOF and, in turn, shorter RTE regardless of condition.\n\n\nIn addition to testing these hypotheses, exploratory correlations were calculated among all predictor variables. False discovery rate (FDR) corrections were applied to account for multiple comparisons. A heatmap of significant correlations is presented in Figure 4.\n\n### Descriptive Statistics\n\n\n\n\nTable 1 shows the descriptive statistics for the primary variables of interest. Figure 1 shows the distribution of RTE values across all participants. The **black line** represents the actual recording length (13:13), and the **<span style=\"color:#FD6467\">pink line</span>** marks the group mean RTE (13:11). Remarkably, the group average mean was within 2 seconds of the true duration. A non-parametric bootstrap test using 10,000 resamples (*N* = 99 per resample) yielded a marginally significant result (*p* = 0.06), suggesting a potential *wisdom of the crowd* effect, a phenomenon in which aggregate judgments converge on a correct value, as documented in other domains [@surowiecki2004].\n\n\n\nInterestingly, 22 out of 99 participants (22%) provided RTEs in exact one-minute increments, despite being prompted to enter responses in both minutes and seconds. Additionally, 52 out of 99 participants (53%) reported RTEs divisible by 30 seconds. The most common RTE values were:\n\n- 900 seconds (15:00): 9 participants  \n- 930 seconds (15:30): 7 participants  \n- 450 seconds (7:30): 6 participants  \n- 630 seconds (10:30): 6 participants  \n- 600 seconds (10:00): 5 participants\n\n<br>\n\n<span style=\"font-size: 90%; color:#555555;\">Table 1. Descriptive Statistics for Primary Variables: RTE = retrospective time estimate, TP = time passage, <br> LOF = level of focus, O = openness, C = conscientiousness, E = extraversion, A = agreeableness, N = neuroticism, MWB = mental well-being, MA = mindful attention, Sleepy = sleepiness.</span>\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(dplyr)\n\nget_summary_stats <- function(data, vars) {\n  data %>%\n    select(all_of(vars)) %>%\n    pivot_longer(cols = everything(), names_to = \"variable\", values_to = \"value\") %>%\n    group_by(variable) %>%\n    summarise(\n      Mean = mean(value, na.rm = TRUE),\n      SD   = sd(value, na.rm = TRUE),\n      Min  = min(value, na.rm = TRUE),\n      Max  = max(value, na.rm = TRUE),\n      .groups = \"drop\"\n    )\n}\n\n\ndescriptives <- get_summary_stats(MTP_data, c(\n  \"rte\", \"lof\", \"tp\",\n  \"bfio\", \"bfic\", \"bfie\", \"bfia\", \"bfin\",\n  \"maas_score\", \"mwb_score\", \"sleep_score\"\n))\n\n# Define label order\nordered_labels <- c(\n  \"rte\" = \"RTE\",\n  \"tp\" = \"TP\",\n  \"lof\" = \"LOF\",\n  \"bfio\" = \"O\",\n  \"bfic\" = \"C\",\n  \"bfie\" = \"E\",\n  \"bfia\" = \"A\",\n  \"bfin\" = \"N\",\n  \"mwb_score\" = \"MWB\",\n  \"maas_score\" = \"MA\",\n  \"sleep_score\" = \"Sleepy\"\n)\n\n# Prepare data\ndescriptives <- descriptives %>%\n  mutate(\n    Variable = factor(variable, levels = names(ordered_labels), labels = ordered_labels)\n  ) %>%\n  arrange(Variable) %>%\n  select(Variable, Mean, SD, Min, Max)\n\n# Display table\nkable(descriptives, digits = 2) %>%\n  kable_styling(\n    full_width = FALSE,\n    position = \"left\",\n    bootstrap_options = c(\"striped\", \"hover\"),\n    stripe_color = \"lightblue\"\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; \">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Variable </th>\n   <th style=\"text-align:right;\"> Mean </th>\n   <th style=\"text-align:right;\"> SD </th>\n   <th style=\"text-align:right;\"> Min </th>\n   <th style=\"text-align:right;\"> Max </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> RTE </td>\n   <td style=\"text-align:right;\"> 790.84 </td>\n   <td style=\"text-align:right;\"> 259.71 </td>\n   <td style=\"text-align:right;\"> 180 </td>\n   <td style=\"text-align:right;\"> 1428 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TP </td>\n   <td style=\"text-align:right;\"> 4.90 </td>\n   <td style=\"text-align:right;\"> 1.71 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 9 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> LOF </td>\n   <td style=\"text-align:right;\"> 5.08 </td>\n   <td style=\"text-align:right;\"> 2.22 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 9 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> O </td>\n   <td style=\"text-align:right;\"> 7.40 </td>\n   <td style=\"text-align:right;\"> 1.77 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> C </td>\n   <td style=\"text-align:right;\"> 7.62 </td>\n   <td style=\"text-align:right;\"> 1.40 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> E </td>\n   <td style=\"text-align:right;\"> 7.12 </td>\n   <td style=\"text-align:right;\"> 1.88 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> A </td>\n   <td style=\"text-align:right;\"> 7.55 </td>\n   <td style=\"text-align:right;\"> 1.57 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> N </td>\n   <td style=\"text-align:right;\"> 6.56 </td>\n   <td style=\"text-align:right;\"> 2.19 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> MWB </td>\n   <td style=\"text-align:right;\"> 50.88 </td>\n   <td style=\"text-align:right;\"> 6.99 </td>\n   <td style=\"text-align:right;\"> 35 </td>\n   <td style=\"text-align:right;\"> 67 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> MA </td>\n   <td style=\"text-align:right;\"> 56.13 </td>\n   <td style=\"text-align:right;\"> 9.41 </td>\n   <td style=\"text-align:right;\"> 38 </td>\n   <td style=\"text-align:right;\"> 79 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sleepy </td>\n   <td style=\"text-align:right;\"> 8.35 </td>\n   <td style=\"text-align:right;\"> 3.91 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 20 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n<br>\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nlibrary(wesanderson)\n\n# Mean RTE predictions for entire sample regardless of condition\n\ngrandbudapest3 <- wes_palette(\"GrandBudapest1\", 3)\nsingle_color <- grandbudapest3[1]\nmean_color <- grandbudapest3[2]    # red from palette\nactual_color <- grandbudapest3[3]  # dark brown from palette\n\n\nmean_rte <- mean(MTP_data$rte, na.rm = TRUE)\nactual_length <- 13 * 60 + 13\n\n\nmean_min <- floor(mean_rte / 60)\nmean_sec <- round(mean_rte %% 60)\nactual_min <- floor(actual_length / 60)\nactual_sec <- round(actual_length %% 60)\n\n\nggplot(MTP_data, aes(x = rte)) +\n  geom_histogram(binwidth = 45, \n                 fill = grandbudapest3[1], \n                 color = \"white\", \n                 alpha = 0.6) +\n  geom_vline(aes(xintercept = mean_rte + 5), \n             color = mean_color, \n             linetype = \"solid\", \n             size = 1) +\n  geom_vline(aes(xintercept = actual_length - 5), \n             color = actual_color, \n             linetype = \"solid\", \n             size = 1) +\n  scale_x_continuous(\n    labels = function(x) round(x / 60, 2),\n    breaks = seq(0, max(MTP_data$rte, na.rm = TRUE), by = 240)\n  ) +\n  labs(\n    title = \"<b>Estimated duration across all 99 participants</b>\",\n    subtitle = paste0(\n  \"<span style='color:\", mean_color, \";'><b>Mean estimated length</b></span>: \",\n  mean_min, \" min \", mean_sec, \" sec; \",\n  \"<b>Actual recording lengths</b>: \",\n  actual_min, \" min \", actual_sec, \" sec\"\n  ),\n    x = \"Duration (in minutes)\",\n    y = \"\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = ggtext::element_markdown(size = 16),\n    plot.subtitle = ggtext::element_markdown(size = 12),\n    axis.text.x = element_text(size = 10),\n    axis.title.x = element_text(size = 11),    \n    axis.text.y = element_text(size = 10),    \n    axis.ticks.y = element_line(),           \n    panel.grid.minor = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![Distribution of RTE values across all participants. The <b>black line</b> represents the actual recording length (13:13), and the <span style=\"color:#FD6467\"><b>pink line</b></span> marks the mean estimate (13:11).](index_files/figure-html/fig-rte-histogram-1.png){#fig-rte-histogram fig-align='left' width=672}\n:::\n:::\n\n\n\n<br>\n\nTable 2 presents descriptive statistics for RTE values separated by condition. Figure 2 displays a density ridge plot illustrating the distribution of RTE scores across the three listening conditions, with condition means marked by central points. Notable variation in mean RTE across conditions prompted further analysis to determine whether the type of audio recording significantly influenced participants’ RTEs.\n\n<span style=\"font-size: 90%; color:#555555;\">Table 2. Descriptive Statistics for Retrospective Time Estimation (in seconds) by Condition.</span>\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(dplyr)\n\n\n# Getting summary stats by condition \nsummary_stats <- MTP_data %>% \n  group_by(condition) %>% \n  summarize(\n    mean_rte = mean(rte, na.rm = TRUE),\n    sd_rate = sd(rte, na.rm = TRUE),\n    n = n(),\n    min_rate = min(rte, na.rm = TRUE),\n    max_rate = max(rte, na.rm = TRUE)\n  )\n\n# Clean and relabel summary table\nsummary_stats_clean <- summary_stats %>%\n  mutate(condition = case_when(\n    condition == 1 ~ \"Short story\",\n    condition == 2 ~ \"Mindfulness meditation\",\n    condition == 3 ~ \"Mind wandering\",\n    TRUE ~ as.character(condition)\n  )) %>%\n  rename(\n    Condition = condition,\n    Mean = mean_rte,\n    SD = sd_rate,\n    Min = min_rate,\n    Max = max_rate,\n    N = n\n  ) %>%\n  mutate(\n    Mean = round(Mean, 2),\n    SD = round(SD, 2),\n    Min = round(Min),\n    Max = round(Max)\n  )\n\n# Display the formatted table\nsummary_stats_clean %>%\n  kable(\n    digits = 2,\n    align = \"lccccc\",\n    escape = FALSE\n  ) %>%\n  kable_styling(\n    full_width = FALSE,\n    bootstrap_options = c(\"striped\", \"hover\"),\n    position = \"left\"\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; \">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Condition </th>\n   <th style=\"text-align:center;\"> Mean </th>\n   <th style=\"text-align:center;\"> SD </th>\n   <th style=\"text-align:center;\"> N </th>\n   <th style=\"text-align:center;\"> Min </th>\n   <th style=\"text-align:center;\"> Max </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Short story </td>\n   <td style=\"text-align:center;\"> 781.73 </td>\n   <td style=\"text-align:center;\"> 249.79 </td>\n   <td style=\"text-align:center;\"> 33 </td>\n   <td style=\"text-align:center;\"> 450 </td>\n   <td style=\"text-align:center;\"> 1428 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Mindfulness meditation </td>\n   <td style=\"text-align:center;\"> 763.12 </td>\n   <td style=\"text-align:center;\"> 252.43 </td>\n   <td style=\"text-align:center;\"> 33 </td>\n   <td style=\"text-align:center;\"> 180 </td>\n   <td style=\"text-align:center;\"> 1225 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Mind wandering </td>\n   <td style=\"text-align:center;\"> 827.67 </td>\n   <td style=\"text-align:center;\"> 279.60 </td>\n   <td style=\"text-align:center;\"> 33 </td>\n   <td style=\"text-align:center;\"> 405 </td>\n   <td style=\"text-align:center;\"> 1380 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n<br>\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\n# Density ridge plot of rte by condition\n\nlibrary(ggridges)\nlibrary(ggtext)\nlibrary(dplyr)\n\n# Set condition factor levels and labels (reversed to put SS at the top)\nMTP_data$condition <- factor(MTP_data$condition,\n                             levels = c(3, 2, 1),\n                             labels = c(\"Mind wandering\",\n                                        \"Mindfulness meditation\",\n                                        \"Short story\"))\n\n# Get colors\ngrandbudapest3 <- wes_palette(\"GrandBudapest1\", 3)\n\n# Compute means for labeling\nmeans_df <- MTP_data %>%\n  group_by(condition) %>%\n  summarize(mean_rte = mean(rte, na.rm = TRUE)) %>%\n  mutate(\n    mean_min = floor(mean_rte / 60),\n    mean_sec = round(mean_rte %% 60),\n    label = paste0(mean_min, \"m \", mean_sec, \"s\")\n  )\n\n# Dynamically get factor levels (in plotting order)\ncondition_levels <- levels(MTP_data$condition)\n\n# Assign abbreviations (must match condition_levels order)\nabbrev_labels <- c(\"MW\", \"MM\", \"SS\")  # Adjust if you ever change level order\n\n# Create matching HTML labels\ny_labels <- paste0(\n  \"<span style='color:\", grandbudapest3, \";'><b>\", abbrev_labels, \"</b></span>\"\n)\n\n# Final plot\nggplot(MTP_data, aes(x = rte, y = condition, fill = condition)) +\n  geom_density_ridges(alpha = 0.6, scale = 0.8) +\n  geom_point(data = means_df, aes(x = mean_rte, y = condition),\n             color = \"black\", size = 3) +\n  geom_text(data = means_df,\n            aes(x = mean_rte, y = condition, label = label),\n            nudge_y = -0.1,\n            size = 3,\n            color = \"black\") +\n  scale_x_continuous(\n    limits = c(0, 1800),\n    labels = function(x) round(x / 60, 2),\n    breaks = seq(0, 1800, by = 240)\n  ) +\n  scale_y_discrete(\n    limits = condition_levels,\n    labels = setNames(y_labels, condition_levels)\n  ) +\n  scale_fill_manual(values = grandbudapest3) +\n  labs(\n    title = \"<b>Estimated duration of recording (means included)</b>\",\n    subtitle = paste0(\n      \"By <span style='color:\", grandbudapest3[3], \";'><b>short story</b></span>, \",\n      \"<span style='color:\", grandbudapest3[2], \";'><b>mindfulness meditation</b></span>, and \",\n      \"<span style='color:\", grandbudapest3[1], \";'><b>mind wandering</b></span>\"\n    ),\n    x = \"Estimated duration (in minutes)\",\n    y = \"\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = ggtext::element_markdown(size = 14),\n    plot.subtitle = ggtext::element_markdown(size = 12),\n    axis.text.y = ggtext::element_markdown(size = 10),\n    legend.position = \"none\",\n    panel.grid.minor = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![Distribution of retrospective time estimates (RTE) by condition.](index_files/figure-html/fig-rte-by-condition-1.png){#fig-rte-by-condition fig-align='left' width=672}\n:::\n:::\n\n\n\n### Manipulation Check\n\n\n\n\nTo confirm that the experimental condition successfully influenced participants’ subjective level of focus (LOF), a one-way ANOVA was conducted with LOF as the dependent variable and condition as the independent variable. The analysis revealed a highly significant effect of condition on LOF, *F*(2, 96) = 53.47, *p* <0.001, indicating that perceived focus varied substantially by condition.\n\nMean LOF scores were lowest in the MW condition (*M* = 2.58, *SD* = 1.45), higher in the MM condition (*M* = 5.43, *SD* = 1.82), and highest in the SS condition (*M* = 6.34, *SD* = 1.77). Post-hoc Tukey tests confirmed that each condition differed significantly from the others: participants in the MW condition reported substantially lower LOF than those in both the MM (Mean difference = 2.85, *p* < .001) and SS conditions (Mean difference = 3.76, *p* < .001). Participants in the SS condition also reported slightly higher LOF than those in the MM condition (Mean difference = 0.91, *p* = .048).\n\nWhile the manipulation succeeded in producing the lowest LOF in the MW condition as intended, it did not produce the highest LOF in the MM condition, as was hypothesized. Instead, participants in the SS condition reported the greatest level of focus. The distribution of LOF by condition is visualized in Figure 3.\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(ggridges)\nlibrary(wesanderson)\nlibrary(ggtext)\n\ngrandbudapest3 <- wes_palette(\"GrandBudapest1\", 3)\n\ny_labels <- c(\n  paste0(\"<span style='color:\", grandbudapest3[1], \";'><b>MW</b></span>\"),\n  paste0(\"<span style='color:\", grandbudapest3[2], \";'><b>MM</b></span>\"),\n  paste0(\"<span style='color:\", grandbudapest3[3], \";'><b>SS</b></span>\")\n)\n\nlof_means_df <- MTP_data %>%\n  group_by(condition) %>%\n  summarize(mean_lof = mean(lof, na.rm = TRUE), .groups = \"drop\") %>%\n  mutate(label = round(mean_lof, 2))\n\nMTP_data %>%\n  ggplot(aes(x = lof, y = condition, fill = condition)) +\n  geom_density_ridges(scale = 1, alpha = 0.7) +\n  geom_point(data = lof_means_df, aes(x = mean_lof, y = condition),\n             color = \"black\", size = 3) +\n  geom_text(data = lof_means_df,\n          aes(x = mean_lof, y = condition, label = label),\n          nudge_y = -0.1,\n          size = 3,\n          color = \"black\") +\n  scale_fill_manual(values = grandbudapest3) +\n  scale_y_discrete(labels = y_labels) +\n  scale_x_continuous(breaks = seq(0, 10, by = 2), limits = c(0, 10)) +\n  labs(\n    title = \"<b>Perceived level of focus</b>\",\n    subtitle = paste0(\n      \"By <span style='color:\", grandbudapest3[3], \";'><b>short story</b></span>, \",\n      \"<span style='color:\", grandbudapest3[2], \";'><b>mindfulness meditation</b></span>, and \",\n      \"<span style='color:\", grandbudapest3[1], \";'><b>mind wandering</b></span>\"\n    ),\n    x = \"Level of focus\",\n    y = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = ggtext::element_markdown(size = 14),\n    plot.subtitle = ggtext::element_markdown(size = 12),\n    axis.text.y = ggtext::element_markdown(size = 10),\n    legend.position = \"none\",\n    panel.grid.minor = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![Figure 3. Distribution of subjective level of focus (LOF) by condition, with group means noted.](index_files/figure-html/unnamed-chunk-5-1.png){fig-align='left' width=768}\n:::\n:::\n\n\n<br>\n\n# Inferential Analysis\n\n\n\n\nBefore conducting inferential tests, we examined descriptive statistics for the primary predictors. Participants reported moderate levels of perceived focus during the session (*M* = 5.08, *SD* = 2.22) and moderate TP (*M* = 4.9, *SD* = 1.71), suggesting a wide range of attentional and temporal experiences. Trait measures were similarly variable, with participants reporting moderate levels of mindful awareness (*M* = 56.13, *SD* = 9.41), mental well-being (*M* = 50.88, *SD* = 6.99), and daytime sleepiness (*M* = 8.35, *SD* = 3.91).\n\n\n\n\nTo assess whether experimental condition had a statistically significant effect on RTE, a one-way ANOVA was conducted. The results revealed no main effect of condition on RTE, *F*(2, 96) = 0.53, *p* = 0.59.\n\n\n\nTo better understand whether any predictors influenced RTE, a multiple linear regression model was constructed using all measured variables. Predictors included perceived level of focus (LOF), sleepiness, mental well-being, mindful awareness, time passage, and the Big Five personality traits. Assumptions of linearity, independence, and homoscedasticity were not violated. The model did not explain a significant proportion of variance in RTE, *F*(12, 86) = 0.32, *p* = 0.98, *R²* = 0.04, adjusted *R²* = -0.09. None of the individual predictors reached statistical significance (*all p* > .28).\n\nTo explore whether a subset of variables might meaningfully predict RTE, an exploratory stepwise regression was conducted using both forward and backward selection. Surprisingly, the procedure converged on an intercept-only model, meaning that none of the included predictors improved model fit. The best-fitting model simply predicted RTE using the overall mean, without including any explanatory variables. This suggests that none of the measured predictors accounted for any meaningful variance in participants’ RTEs.\n\n### Exploratory Correlations Among Predictor Variables\n\nAlthough none of the predictors were significant in the confirmatory models, exploratory correlations were computed to identify potential associations that could guide future hypothesis-driven research. A correlation matrix revealed several notable relationships among the predictor variables. These are visualized in Figure 4, with significance levels denoted by the number of asterisks.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(dplyr)\nlibrary(tibble)\nlibrary(wesanderson)\n\nwes_colors <- wes_palette(\"Zissou1\", 100, type = \"continuous\")\n\n# Your correlation results\ncor_results <- tribble(\n  ~var1, ~var2, ~correlation, ~p_value, ~p_value_fdr,\n  \"sleep_score\", \"maas_score\", -0.5673760, 9.16e-10, 9.16e-09,\n  \"sleep_score\", \"mwb_score\", -0.5214855, 3.12e-08, 1.56e-07,\n  \"bfie\", \"mwb_score\", 0.5042635, 1.03e-07, 3.27e-07,\n  \"bfin\", \"mwb_score\", -0.5006882, 1.31e-07, 3.27e-07,\n  \"tp\", \"lof\", 0.4719703, 8.15e-07, 1.63e-06,\n  \"lof\", \"bfin\", -0.3392185, 7.14e-04, 9.30e-04,\n  \"bfin\", \"sleep_score\", 0.4594901, 1.72e-06, 2.86e-06,\n  \"mwb_score\", \"maas_score\", 0.4343542, 7.06e-06, 1.01e-05,\n  \"sleep_score\", \"bfic\", -0.3281750, 9.13e-04, 1.14e-03,\n  \"bfic\", \"maas_score\", 0.3163274, 1.42e-03, 1.58e-03,\n  \"bfie\", \"sleep_score\", -0.2294483, 2.23e-02, 2.23e-02\n)\n\n# Human-readable labels\nlabel_map <- c(\n  \"sleep_score\" = \"Sleepiness\",\n  \"mwb_score\" = \"Mental well-being\",\n  \"maas_score\" = \"Mindful attention\",\n  \"lof\" = \"Level of focus\",\n  \"bfic\" = \"Conscientiousness\",\n  \"bfie\" = \"Extraversion\",\n  \"bfin\" = \"Neuroticism\",\n  \"tp\" = \"Time passage\"\n)\n\n# Add stars and formatted labels\ncor_results <- cor_results %>%\n  mutate(\n    var1_label = label_map[var1],\n    var2_label = label_map[var2],\n    sig_label = case_when(\n      p_value_fdr < 0.001 ~ \"***\",\n      p_value_fdr < 0.01 ~ \"**\",\n      p_value_fdr < 0.05 ~ \"*\",\n      TRUE ~ \"\"\n    ),\n    text_label = paste0(\n      \"<b>\", var1_label, \" × \", var2_label, \"</b><br>\",\n      \"Correlation: \", round(correlation, 2), sig_label, \"<br>\",\n      \"FDR-adjusted p: \", signif(p_value_fdr, 3)\n    )\n  )\n\n# Build the plot\nheatmap_plot_hover <- ggplot(cor_results, aes(\n  x = var1_label,\n  y = var2_label,\n  fill = correlation,\n  text = text_label\n)) +\n  geom_tile(color = \"white\", linewidth = 0.7) +\n  geom_text(aes(label = paste0(round(correlation, 2), sig_label)),\n            size = 3, color = \"black\") +\n  scale_fill_gradientn(colors = wes_colors, limits = c(-1, 1)) +\n  labs(\n    x = \"\",\n    y = \"\",\n    fill = \"Correlation\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),\n    axis.text.y = element_text(size = 10)\n  )\n\n# Interactive version with styled title\nggplotly(heatmap_plot_hover, tooltip = \"text\", height = 575) %>%\n  layout(\n    title = list(\n      text = paste0(\n        \"<b>Correlation heatmap of predictor variables</b><br>\",\n        \"<span style='font-size:12pt'><b>Significance: *p < .05, **p < .01, ***p < .001</b></span>\"\n      ),\n      x = 0,\n      xanchor = \"left\",\n      pad = list(t = 20, b = 20)\n    ),\n    margin = list(t = 100)\n  )\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"htmlwidget-0f99ee82c22e8485cf2d\" style=\"width:100%;height:556px;\" class=\"plotly html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-0f99ee82c22e8485cf2d\">{\"x\":{\"data\":[{\"x\":[1,2,3,4,5,6,7],\"y\":[1,2,3,4,5,6],\"z\":[[null,null,null,null,null,0.22321032399421636,null],[null,null,null,null,null,null,0.96986561245642788],[null,1,null,null,0.062229695713903764,0.042822702970541818,null],[0.82462749833316151,null,null,0.93476416276182428,null,0,null],[null,null,0.21290508608538602,null,null,null,null],[null,0.31533710730147596,null,null,0.95821971847808896,null,null]],\"text\":[[null,null,null,null,null,\"<b>Sleepiness × Conscientiousness<\\/b><br>Correlation: -0.33**<br>FDR-adjusted p: 0.00114\",null],[null,null,null,null,null,null,\"<b>Time passage × Level of focus<\\/b><br>Correlation: 0.47***<br>FDR-adjusted p: 1.63e-06\"],[null,\"<b>Extraversion × Mental well-being<\\/b><br>Correlation: 0.5***<br>FDR-adjusted p: 3.27e-07\",null,null,\"<b>Neuroticism × Mental well-being<\\/b><br>Correlation: -0.5***<br>FDR-adjusted p: 3.27e-07\",\"<b>Sleepiness × Mental well-being<\\/b><br>Correlation: -0.52***<br>FDR-adjusted p: 1.56e-07\",null],[\"<b>Conscientiousness × Mindful attention<\\/b><br>Correlation: 0.32**<br>FDR-adjusted p: 0.00158\",null,null,\"<b>Mental well-being × Mindful attention<\\/b><br>Correlation: 0.43***<br>FDR-adjusted p: 1.01e-05\",null,\"<b>Sleepiness × Mindful attention<\\/b><br>Correlation: -0.57***<br>FDR-adjusted p: 9.16e-09\",null],[null,null,\"<b>Level of focus × Neuroticism<\\/b><br>Correlation: -0.34***<br>FDR-adjusted p: 0.00093\",null,null,null,null],[null,\"<b>Extraversion × Sleepiness<\\/b><br>Correlation: -0.23*<br>FDR-adjusted p: 0.0223\",null,null,\"<b>Neuroticism × Sleepiness<\\/b><br>Correlation: 0.46***<br>FDR-adjusted p: 2.86e-06\",null,null]],\"colorscale\":[[0,\"#94BAB2\"],[0.042822702970541818,\"#98BDAE\"],[0.062229695713903764,\"#9ABEAC\"],[0.21290508608538602,\"#ACC398\"],[0.22321032399421636,\"#AEC396\"],[0.31533710730147596,\"#B9C786\"],[0.82462749833316151,\"#E5A509\"],[0.93476416276182428,\"#E79205\"],[0.95821971847808896,\"#E88E05\"],[0.96986561245642788,\"#E88C05\"],[1,\"#E98805\"]],\"type\":\"heatmap\",\"showscale\":false,\"autocolorscale\":false,\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[6,6,2,5,7,3,5,4,6,1,2],\"y\":[4,3,3,3,2,5,6,4,1,4,6],\"text\":[\"-0.57***\",\"-0.52***\",\"0.5***\",\"-0.5***\",\"0.47***\",\"-0.34***\",\"0.46***\",\"0.43***\",\"-0.33**\",\"0.32**\",\"-0.23*\"],\"hovertext\":[\"<b>Sleepiness × Mindful attention<\\/b><br>Correlation: -0.57***<br>FDR-adjusted p: 9.16e-09\",\"<b>Sleepiness × Mental well-being<\\/b><br>Correlation: -0.52***<br>FDR-adjusted p: 1.56e-07\",\"<b>Extraversion × Mental well-being<\\/b><br>Correlation: 0.5***<br>FDR-adjusted p: 3.27e-07\",\"<b>Neuroticism × Mental well-being<\\/b><br>Correlation: -0.5***<br>FDR-adjusted p: 3.27e-07\",\"<b>Time passage × Level of focus<\\/b><br>Correlation: 0.47***<br>FDR-adjusted p: 1.63e-06\",\"<b>Level of focus × Neuroticism<\\/b><br>Correlation: -0.34***<br>FDR-adjusted p: 0.00093\",\"<b>Neuroticism × Sleepiness<\\/b><br>Correlation: 0.46***<br>FDR-adjusted p: 2.86e-06\",\"<b>Mental well-being × Mindful attention<\\/b><br>Correlation: 0.43***<br>FDR-adjusted p: 1.01e-05\",\"<b>Sleepiness × Conscientiousness<\\/b><br>Correlation: -0.33**<br>FDR-adjusted p: 0.00114\",\"<b>Conscientiousness × Mindful attention<\\/b><br>Correlation: 0.32**<br>FDR-adjusted p: 0.00158\",\"<b>Extraversion × Sleepiness<\\/b><br>Correlation: -0.23*<br>FDR-adjusted p: 0.0223\"],\"textfont\":{\"size\":11.338582677165356,\"color\":\"rgba(0,0,0,1)\"},\"type\":\"scatter\",\"mode\":\"text\",\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1],\"y\":[1],\"name\":\"145f2df95d5302cca81ea96a5523250b\",\"type\":\"scatter\",\"mode\":\"markers\",\"opacity\":0,\"hoverinfo\":\"skip\",\"showlegend\":false,\"marker\":{\"color\":[0,1],\"colorscale\":[[0,\"#3A9AB2\"],[0.0033444816053511683,\"#3C9BB2\"],[0.0066889632107023367,\"#3D9BB3\"],[0.010033444816053505,\"#3F9CB3\"],[0.013377926421404673,\"#419DB4\"],[0.016722408026755842,\"#429DB4\"],[0.02006688963210701,\"#449EB5\"],[0.023411371237458178,\"#469FB5\"],[0.026755852842809347,\"#48A0B6\"],[0.030100334448160515,\"#4AA1B6\"],[0.033444816053511683,\"#4CA2B7\"],[0.036789297658862852,\"#4DA2B7\"],[0.04013377926421402,\"#4FA3B8\"],[0.043478260869565188,\"#51A4B8\"],[0.046822742474916357,\"#52A5B9\"],[0.050167224080267581,\"#54A6B9\"],[0.053511705685618749,\"#56A7BA\"],[0.056856187290969917,\"#58A7BA\"],[0.060200668896321086,\"#5AA8BB\"],[0.063545150501672254,\"#5BA9BB\"],[0.066889632107023422,\"#5DA9BC\"],[0.070234113712374591,\"#5FAABC\"],[0.073578595317725759,\"#60ABBD\"],[0.076923076923076927,\"#62ACBD\"],[0.080267558528428096,\"#64ADBE\"],[0.083612040133779264,\"#66AEBE\"],[0.086956521739130432,\"#68AEBF\"],[0.090301003344481601,\"#6AAFBF\"],[0.093645484949832769,\"#6BB0BF\"],[0.096989966555183937,\"#6DB1C0\"],[0.10033444816053511,\"#6FB2C0\"],[0.10367892976588627,\"#70B2C0\"],[0.10702341137123744,\"#71B2BF\"],[0.11036789297658861,\"#72B2BF\"],[0.11371237458193978,\"#73B2BF\"],[0.11705685618729095,\"#74B3BE\"],[0.12040133779264217,\"#76B3BE\"],[0.12374581939799334,\"#77B3BE\"],[0.12709030100334451,\"#78B4BD\"],[0.13043478260869568,\"#79B4BD\"],[0.13377926421404684,\"#7AB4BD\"],[0.13712374581939801,\"#7BB5BC\"],[0.14046822742474918,\"#7DB5BC\"],[0.14381270903010035,\"#7EB5BC\"],[0.14715719063545152,\"#7FB6BB\"],[0.15050167224080269,\"#80B6BB\"],[0.15384615384615385,\"#81B6BB\"],[0.15719063545150502,\"#82B6BA\"],[0.16053511705685619,\"#83B6BA\"],[0.16387959866220736,\"#84B6BA\"],[0.16722408026755853,\"#85B7B9\"],[0.1705685618729097,\"#87B7B9\"],[0.17391304347826086,\"#88B7B9\"],[0.17725752508361203,\"#89B8B8\"],[0.1806020066889632,\"#8AB8B8\"],[0.18394648829431437,\"#8BB8B8\"],[0.18729096989966554,\"#8CB9B7\"],[0.19063545150501671,\"#8DB9B6\"],[0.19397993311036787,\"#8FB9B6\"],[0.19732441471571904,\"#90BAB5\"],[0.20066889632107021,\"#91BAB5\"],[0.20401337792642138,\"#91BAB5\"],[0.20735785953177255,\"#92BAB4\"],[0.21070234113712372,\"#93BAB3\"],[0.21404682274247488,\"#93BAB3\"],[0.21739130434782605,\"#94BBB2\"],[0.22073578595317722,\"#95BBB1\"],[0.22408026755852839,\"#95BBB1\"],[0.22742474916387956,\"#96BCB0\"],[0.23076923076923073,\"#97BCAF\"],[0.23411371237458189,\"#97BCAF\"],[0.23745819397993312,\"#98BDAE\"],[0.24080267558528429,\"#99BDAD\"],[0.24414715719063546,\"#99BDAD\"],[0.24749163879598662,\"#9ABEAC\"],[0.25083612040133779,\"#9BBEAC\"],[0.25418060200668896,\"#9BBEAC\"],[0.25752508361204013,\"#9CBEAB\"],[0.2608695652173913,\"#9DBFAA\"],[0.26421404682274247,\"#9DBFAA\"],[0.26755852842809363,\"#9EBFA9\"],[0.2709030100334448,\"#9FBFA8\"],[0.27424749163879597,\"#9FBFA8\"],[0.27759197324414714,\"#A0BFA7\"],[0.28093645484949831,\"#A1C0A6\"],[0.28428093645484948,\"#A1C0A6\"],[0.28762541806020064,\"#A2C0A5\"],[0.29096989966555181,\"#A3C1A4\"],[0.29431438127090298,\"#A3C1A4\"],[0.29765886287625415,\"#A4C1A3\"],[0.30100334448160537,\"#A5C2A2\"],[0.30434782608695654,\"#A5C2A1\"],[0.30769230769230771,\"#A6C2A0\"],[0.31103678929765888,\"#A7C29F\"],[0.31438127090301005,\"#A8C29E\"],[0.31772575250836121,\"#A9C29D\"],[0.32107023411371238,\"#AAC39C\"],[0.32441471571906355,\"#AAC39B\"],[0.32775919732441472,\"#ABC399\"],[0.33110367892976589,\"#ACC398\"],[0.33444816053511706,\"#ADC397\"],[0.33779264214046822,\"#AEC396\"],[0.34113712374581939,\"#AFC495\"],[0.34448160535117056,\"#AFC494\"],[0.34782608695652173,\"#B0C492\"],[0.3511705685618729,\"#B1C591\"],[0.35451505016722407,\"#B1C590\"],[0.35785953177257523,\"#B2C58F\"],[0.3612040133779264,\"#B3C58E\"],[0.36454849498327757,\"#B4C58D\"],[0.36789297658862874,\"#B5C58B\"],[0.37123745819397991,\"#B6C68A\"],[0.37458193979933108,\"#B6C689\"],[0.37792642140468224,\"#B7C688\"],[0.38127090301003341,\"#B8C787\"],[0.38461538461538458,\"#B9C786\"],[0.38795986622073581,\"#BAC785\"],[0.39130434782608697,\"#BAC784\"],[0.39464882943143814,\"#BBC783\"],[0.39799331103678931,\"#BCC781\"],[0.40133779264214048,\"#BDC87F\"],[0.40468227424749165,\"#BEC87E\"],[0.40802675585284282,\"#BFC87C\"],[0.41137123745819398,\"#C0C87A\"],[0.41471571906354515,\"#C1C879\"],[0.41806020066889632,\"#C2C877\"],[0.42140468227424749,\"#C3C875\"],[0.42474916387959866,\"#C4C874\"],[0.42809364548494983,\"#C5C872\"],[0.43143812709030099,\"#C6C970\"],[0.43478260869565216,\"#C7C96F\"],[0.43812709030100333,\"#C8C96D\"],[0.4414715719063545,\"#C9C96B\"],[0.44481605351170567,\"#CAC96A\"],[0.44816053511705684,\"#CBC968\"],[0.451505016722408,\"#CCC967\"],[0.45484949832775917,\"#CDC965\"],[0.45819397993311034,\"#CEC963\"],[0.46153846153846151,\"#D0C962\"],[0.46488294314381268,\"#D1C960\"],[0.46822742474916385,\"#D2C95E\"],[0.47157190635451507,\"#D3CA5C\"],[0.47491638795986624,\"#D4CA5A\"],[0.47826086956521741,\"#D5CA58\"],[0.48160535117056857,\"#D6CA57\"],[0.48494983277591974,\"#D7CA55\"],[0.48829431438127091,\"#D8CA53\"],[0.49163879598662208,\"#D9CA52\"],[0.49498327759197325,\"#DACA50\"],[0.49832775919732442,\"#DBCA4E\"],[0.50167224080267558,\"#DBC94C\"],[0.50501672240802675,\"#DCC94A\"],[0.50836120401337792,\"#DCC848\"],[0.51170568561872909,\"#DDC846\"],[0.51505016722408026,\"#DDC744\"],[0.51839464882943143,\"#DDC642\"],[0.52173913043478259,\"#DDC640\"],[0.52508361204013376,\"#DDC53E\"],[0.52842809364548493,\"#DDC43C\"],[0.5317725752508361,\"#DEC43A\"],[0.53511705685618727,\"#DEC338\"],[0.53846153846153844,\"#DEC236\"],[0.5418060200668896,\"#DFC234\"],[0.54515050167224077,\"#DFC131\"],[0.54849498327759194,\"#DFC02F\"],[0.55183946488294311,\"#DFC02D\"],[0.55518394648829428,\"#DFBF2B\"],[0.55852842809364545,\"#DFBE29\"],[0.56187290969899661,\"#E0BE27\"],[0.56521739130434778,\"#E0BD25\"],[0.56856187290969895,\"#E0BC23\"],[0.57190635451505012,\"#E1BC21\"],[0.57525083612040129,\"#E1BB1F\"],[0.57859531772575246,\"#E1BA1D\"],[0.58193979933110362,\"#E2BA1B\"],[0.58528428093645479,\"#E2B918\"],[0.58862876254180596,\"#E2B816\"],[0.59197324414715713,\"#E2B815\"],[0.5953177257525083,\"#E2B712\"],[0.59866220735785947,\"#E2B611\"],[0.60200668896321075,\"#E3B610\"],[0.60535117056856191,\"#E3B50F\"],[0.60869565217391308,\"#E3B40F\"],[0.61204013377926425,\"#E3B30E\"],[0.61538461538461542,\"#E3B10E\"],[0.61872909698996659,\"#E3B00E\"],[0.62207357859531776,\"#E4AF0D\"],[0.62541806020066892,\"#E4AE0D\"],[0.62876254180602009,\"#E4AD0D\"],[0.63210702341137126,\"#E4AC0C\"],[0.63545150501672243,\"#E4AB0B\"],[0.6387959866220736,\"#E4AA0B\"],[0.64214046822742477,\"#E4A90A\"],[0.64548494983277593,\"#E4A80A\"],[0.6488294314381271,\"#E4A70A\"],[0.65217391304347827,\"#E5A609\"],[0.65551839464882944,\"#E5A509\"],[0.65886287625418061,\"#E5A409\"],[0.66220735785953178,\"#E5A308\"],[0.66555183946488294,\"#E5A208\"],[0.66889632107023411,\"#E5A108\"],[0.67224080267558528,\"#E6A007\"],[0.67558528428093645,\"#E69F07\"],[0.67892976588628762,\"#E69E07\"],[0.68227424749163879,\"#E69D06\"],[0.68561872909698995,\"#E69C06\"],[0.68896321070234112,\"#E69B06\"],[0.69230769230769229,\"#E69A05\"],[0.69565217391304346,\"#E69905\"],[0.69899665551839463,\"#E69705\"],[0.7023411371237458,\"#E79605\"],[0.70568561872909696,\"#E79505\"],[0.70903010033444813,\"#E79405\"],[0.7123745819397993,\"#E79305\"],[0.71571906354515047,\"#E79205\"],[0.71906354515050164,\"#E79105\"],[0.72240802675585281,\"#E89005\"],[0.72575250836120397,\"#E88F05\"],[0.72909698996655514,\"#E88E05\"],[0.73244147157190631,\"#E88D05\"],[0.73578595317725748,\"#E88C05\"],[0.73913043478260865,\"#E88B05\"],[0.74247491638795982,\"#E98A05\"],[0.74581939799331098,\"#E98905\"],[0.74916387959866215,\"#E98905\"],[0.75250836120401332,\"#E98805\"],[0.75585284280936449,\"#E98705\"],[0.75919732441471566,\"#E98605\"],[0.76254180602006683,\"#E98505\"],[0.76588628762541799,\"#EA8405\"],[0.76923076923076916,\"#EA8305\"],[0.77257525083612044,\"#EA8205\"],[0.77591973244147161,\"#EA8105\"],[0.77926421404682278,\"#EA8005\"],[0.78260869565217395,\"#EA7F05\"],[0.78595317725752512,\"#EB7E05\"],[0.78929765886287628,\"#EB7D05\"],[0.79264214046822745,\"#EB7C05\"],[0.79598662207357862,\"#EB7B05\"],[0.79933110367892979,\"#EB7A05\"],[0.80267558528428096,\"#EB7905\"],[0.80602006688963213,\"#EC7804\"],[0.80936454849498329,\"#EC7604\"],[0.81270903010033446,\"#EC7504\"],[0.81605351170568563,\"#EC7404\"],[0.8193979933110368,\"#EC7304\"],[0.82274247491638797,\"#EC7204\"],[0.82608695652173914,\"#EC7104\"],[0.8294314381270903,\"#EC7004\"],[0.83277591973244147,\"#EC6E04\"],[0.83612040133779264,\"#ED6D04\"],[0.83946488294314381,\"#ED6C04\"],[0.84280936454849498,\"#ED6B04\"],[0.84615384615384615,\"#ED6A04\"],[0.84949832775919731,\"#ED6904\"],[0.85284280936454848,\"#ED6704\"],[0.85618729096989965,\"#ED6603\"],[0.85953177257525082,\"#ED6503\"],[0.86287625418060199,\"#ED6303\"],[0.86622073578595316,\"#EE6203\"],[0.86956521739130432,\"#EE6103\"],[0.87290969899665549,\"#EE6003\"],[0.87625418060200666,\"#EE5F03\"],[0.87959866220735783,\"#EE5E03\"],[0.882943143812709,\"#EE5C03\"],[0.88628762541806017,\"#EE5B03\"],[0.88963210702341133,\"#EE5A03\"],[0.8929765886287625,\"#EE5903\"],[0.89632107023411367,\"#EE5803\"],[0.89966555183946484,\"#EE5703\"],[0.90301003344481601,\"#EE5503\"],[0.90635451505016718,\"#EF5302\"],[0.90969899665551834,\"#EF5102\"],[0.91304347826086951,\"#EF4F02\"],[0.91638795986622068,\"#EF4D02\"],[0.91973244147157185,\"#EF4B02\"],[0.92307692307692302,\"#EF4902\"],[0.92642140468227419,\"#EF4702\"],[0.92976588628762535,\"#EF4502\"],[0.93311036789297652,\"#EF4302\"],[0.93645484949832769,\"#EF4101\"],[0.93979933110367886,\"#EF3F01\"],[0.94314381270903014,\"#EF3D01\"],[0.94648829431438131,\"#EF3B01\"],[0.94983277591973247,\"#EF3901\"],[0.95317725752508364,\"#EF3701\"],[0.95652173913043481,\"#F03501\"],[0.95986622073578598,\"#F03301\"],[0.96321070234113715,\"#F03101\"],[0.96655518394648832,\"#F02F00\"],[0.96989966555183948,\"#F02D00\"],[0.97324414715719065,\"#F02B00\"],[0.97658862876254182,\"#F02900\"],[0.97993311036789299,\"#F02700\"],[0.98327759197324416,\"#F02500\"],[0.98662207357859533,\"#F02300\"],[0.98996655518394649,\"#F02100\"],[0.99331103678929766,\"#F01F00\"],[0.99665551839464883,\"#F11D00\"],[1,\"#F11B00\"]],\"colorbar\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"thickness\":23.039999999999996,\"title\":\"Correlation\",\"titlefont\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724},\"tickmode\":\"array\",\"ticktext\":[\"-1.0\",\"-0.5\",\"0.0\",\"0.5\",\"1.0\"],\"tickvals\":[0.0016666666666666668,0.2508333333333333,0.49999999999999994,0.74916666666666665,0.99833333333333329],\"tickfont\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.68949771689498},\"ticklen\":2,\"len\":0.5}},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":100,\"r\":7.3059360730593621,\"b\":69.77991151404089,\"l\":123.86882523868829},\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.40000000000000002,7.5999999999999996],\"tickmode\":\"array\",\"ticktext\":[\"Conscientiousness\",\"Extraversion\",\"Level of focus\",\"Mental well-being\",\"Neuroticism\",\"Sleepiness\",\"Time passage\"],\"tickvals\":[1,2,3,4.0000000000000009,5,6,7],\"categoryorder\":\"array\",\"categoryarray\":[\"Conscientiousness\",\"Extraversion\",\"Level of focus\",\"Mental well-being\",\"Neuroticism\",\"Sleepiness\",\"Time passage\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.6529680365296811,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":13.283520132835205},\"tickangle\":-45,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176002,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.40000000000000002,6.5999999999999996],\"tickmode\":\"array\",\"ticktext\":[\"Conscientiousness\",\"Level of focus\",\"Mental well-being\",\"Mindful attention\",\"Neuroticism\",\"Sleepiness\"],\"tickvals\":[1,2,3,3.9999999999999996,5,6],\"categoryorder\":\"array\",\"categoryarray\":[\"Conscientiousness\",\"Level of focus\",\"Mental well-being\",\"Mindful attention\",\"Neuroticism\",\"Sleepiness\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.6529680365296811,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":13.283520132835205},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176002,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.68949771689498},\"title\":{\"text\":\"Correlation\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}}},\"hovermode\":\"closest\",\"height\":575,\"barmode\":\"relative\",\"title\":{\"text\":\"<b>Correlation heatmap of predictor variables<\\/b><br><span style='font-size:12pt'><b>Significance: *p < .05, **p < .01, ***p < .001<\\/b><\\/span>\",\"x\":0,\"xanchor\":\"left\",\"pad\":{\"t\":20,\"b\":20}}},\"config\":{\"doubleClick\":\"reset\",\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"3e481255cec5\":{\"x\":{},\"y\":{},\"fill\":{},\"text\":{},\"type\":\"heatmap\"},\"3e483f79f0ea\":{\"x\":{},\"y\":{},\"fill\":{},\"text\":{},\"label\":{}}},\"cur_data\":\"3e481255cec5\",\"visdat\":{\"3e481255cec5\":[\"function (y) \",\"x\"],\"3e483f79f0ea\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n<div style=\"font-size: 0.9em; color: #555; margin-top: 0.5em;\">\nFigure 4. Exploratory correlation matrix among predictor variables. Significance levels adjusted using the False Discovery Rate (FDR) method.\n</div>\n\n<br>\n\n# Discussion\n\n\n\nDespite a substantial body of research linking various psychological and cognitive variables to subjective time perception (STP), the present study found no significant predictors of retrospective time estimation (RTE) among the measured variables. This null result is particularly surprising given the considerable variability in RTE responses, which ranged from r min_rte seconds (r min_rte_min minutes) to r max_rte seconds (r max_rte_min.r max_rte_sec minutes), with a normal distribution and no detected outliers. None of the primary hypotheses were supported: Hypothesis A, which predicted that level of focus (LOF) would be associated with shorter RTE, was not confirmed; Hypothesis B, which posited that sleepiness would predict longer RTE via its impact on LOF, also received no support; and Hypothesis C, which proposed that mindful attention would relate positively to LOF and thus predict shorter RTE, was similarly unsupported. Given the wide range of time estimates, one might have expected at least one variable to show a significant association.\n\nSeveral predictors were selected for their theoretical and empirical relevance to STP, including perceived level of focus (LOF), time passage, Big Five personality traits, trait mindfulness (MA), mental well-being (MWB), and sleepiness. The manipulation check showed that participants in the MW condition reported significantly lower LOF than those in the MM and SS conditions. The MM condition produced moderate LOF scores, and the SS condition produced the highest. These results confirmed that the manipulation succeeded in reducing LOF in the MW group but failed to increase it in the MM group as expected.\n\nSeveral possible explanations may account for the absence of a relationship between LOF and RTE:\n\n1. **Mismatch Between Model and Timescale**\nThe internal clock model, which has guided much of the theoretical work on STP, may not generalize well to longer durations such as those used in this study. The model proposes a pacemaker–accumulator system in which pulses are generated over time and counted to infer duration [@treisman1963]. However, this system is typically studied at much shorter time scales (e.g., milliseconds to a few minutes). For durations exceeding five minutes, memory-based models may be more appropriate, as they posit that RTE depends on the number and salience of cognitive events encoded into memory during the interval [@block1997]. These models suggest that more distinct cognitive events yield longer subjective durations, while fewer or less salient events yield shorter ones. The absence of a correlation between LOF and RTE may reflect a fundamental limitation of the internal clock framework at this longer timescale.\n\n2. **Limited Meditation Experience in the Sample**\nThe study did not formally assess participants’ prior experience with mindfulness, but informal debriefings revealed that few had any meditation background. As a result, participants in the MM condition may have lacked the familiarity necessary to effectively engage with the recording. Only one participant explicitly reported prior experience with meditation and showed results consistent with Hypothesis A, but such anecdotal data are insufficient for inference. Future work should include a measure of meditation experience or recruit experienced meditators as a separate group.\n\n3. **Subjective Focus May Not Reflect Objective Focus**\nAnother plausible explanation is that LOF reflects perceived rather than actual attentional engagement. LOF ratings may be influenced by metacognitive prompts or expectations, which could introduce bias. Notably, the MM condition explicitly instructed participants to monitor their focus, which may have led some to become more aware of their distractibility and subsequently underrate their LOF. This aligns with the “introspection illusion” described by @pronin2009, wherein individuals inaccurately assess their own cognitive processes.\n\nThis phenomenon is echoed in reports from novice meditators, who often experience a paradoxical sense that their focus has worsened as they begin to meditate more regularly. This is frequently explained as an increased awareness of mind-wandering rather than an actual decline in attentional control. That is, as attentional metacognition sharpens, one becomes more aware of previously unnoticed distractions. This leads to lower subjective ratings of LOF even amid genuine improvement.\n\nThe distribution of LOF scores supports this interpretation: the MM group exhibited a distinctly bimodal distribution, suggesting polarization in perceived focus. Some participants may have found the meditation highly focusing, while others became more attuned to their distractibility. In contrast, LOF distributions in the SS and MW conditions were both unimodal, possibly because those recordings did not explicitly prompt metacognitive monitoring.\n\nTo improve measurement of attentional engagement in future research, more objective methods such as EEG, pupillometry, or fMRI could be employed [@groot2021]. These tools could help clarify the relationship between subjective and physiological indicators of focus.\n\n### Other Predictors and RTE\n\nThe lack of significant associations between RTE and any other predictors, including sleepiness, well-being, mindfulness, and personality traits, may also reflect issues of timescale sensitivity. While some studies, such as @sen2023, have found that sleep deprivation can lengthen RTE, these effects are not consistently observed across contexts or designs. Similarly, personality traits may exert minimal influence on the type of memory-based processes that underlie longer-duration RTE.\n\n### The Role of Subjective Time Passage (TP)\n\nTP was also included as a potential correlate of RTE. Interestingly, TP ratings were moderately correlated with LOF (*r* = .47, *p* < .001), indicating that participants who felt more focused also tended to report that time passed more quickly. While this seems paradoxical under an internal clock model, it may instead reflect the phenomenology of “flow”, a state of deep engagement where time may seem to accelerate despite sustained attention [@csikszentmihalyi1990]. However, descriptions of flow can also include experiences in which time appears to slow down or even stand still. Further research in this area is needed to clarify the conditions under which focus influences TP.\n\n### Future Directions\n\nFuture research should expand on the current findings by comparing internal clock and memory-based models of time perception, particularly in relation to longer durations. This could involve manipulating or measuring cognitive event density, novelty, or contextual changes, which are core constructs in memory-based accounts.\n\nTo address limitations in subjective self-report, studies could also refine how LOF is measured. This could be done by triangulating self-assessments with behavioral tasks, implicit metrics, or physiological indicators such as EEG, pupillometry, or fMRI, providing a more objective measure of attentional engagement.\n\nAdditionally, future work might also distinguish between trait and state predictors of RTE by employing experience sampling during extended tasks to capture within-subject variation in attention, arousal, or task engagement.\n\nAnother potential direction would be to manipulate whether participants are explicitly instructed to monitor their focus during the task, in order to determine how metacognitive prompting enhances or suppresses perceived focus.\n\nFinally, future studies could explore the phenomenology of flow and its relationship to both time passage and retrospective estimation, using validated flow state scales or structured interviews to clarify how deep engagement modulates subjective duration judgments. Notably, several participants in the current study informally reported feeling tempted to write down markedly different estimates than they ultimately did, suggesting that RTE may involve a more deliberative or conflicted internal process than typically assumed. Incorporating structured qualitative prompts could help uncover the cognitive heuristics participants rely on when estimating elapsed time.\n\n### Limitations\n\nSeveral limitations of the present study warrant consideration. First, participants were drawn from a convenience sample of undergraduate psychology students at a single university, predominantly identifying as European American and within a narrow age range (18–23). These demographic constraints limit the generalizability of the findings to broader populations.\n\nSecond, aside from the retrospective time estimation (RTE) task, all other variables were assessed through self-report measures. While some constructs (MWB and TP) are inherently subjective, others (sleepiness, MA, and LOF) could, in principle, be assessed using objective behavioral or physiological metrics. Reliance on introspective reports may have introduced bias or measurement error, especially in the meditation condition.\n\nThird, although the overall sample size (*N* = 99) was adequate for detecting moderate effects, splitting the sample across three conditions (*n* = 33 per group) reduced statistical power for condition-specific analyses. As a result, smaller or subtler effects may have gone undetected. Future studies should recruit larger samples to increase power for subgroup analyses and interaction effects.\n\nFourth, participants were presumed to have minimal prior experience with mindfulness meditation. Although informal debriefing confirmed this assumption in most cases, meditation experience was not formally measured or controlled. Future research should explicitly assess meditation background and consider comparing novice and experienced practitioners.\n\n<br>\n\n# Conclusion\n\nIn summary, this study contributes to a small but growing body of research examining RTE over longer durations. Despite substantial variation in RTE, no reliable predictors emerged. These null findings highlight potential limitations of commonly used models of time perception and underscore the need for refined and objective measurement techniques, especially when working with introspective variables like focus. Future work should incorporate objective attentional measures, assess individual differences in meditation experience, and consider the unique dynamics of memory-based models when designing long-duration RTE studies.\n\n<br>\n\n## References\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"../../site_libs/plotly-binding-4.10.4/plotly.js\"></script>\n<script src=\"../../site_libs/typedarray-0.1/typedarray.min.js\"></script>\n<script src=\"../../site_libs/jquery-3.5.1/jquery.min.js\"></script>\n<link href=\"../../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n<link href=\"../../site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}