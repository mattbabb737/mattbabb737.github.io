{
  "hash": "27bafc1da6ade0c37b1ab4dd9d727ad0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Web Scraping\"\ndescription: \"Extracting, cleaning, and organizing data from multiple web pages into a structured format.\"\nauthor:\n  - name: Matt Babb\ndate: 06-07-2025\ncategories: [Quarto, R] # self-defined categories\nimage: cheese_table.jpg\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\neditor: source\nembed-resources: true\necho: true\nwarning: false\nerror: false\ncode-fold: true\ncode-tools: true\n---\n\n> **Goal:** Scrape information from <https://www.cheese.com> to obtain a dataset\n> of characteristics about different cheeses, and gain deeper insight into your\n> coding process. ðŸª¤\n\n**Part 1:** Locate and examine the `robots.txt` file for this website. Summarize\nwhat you learn from it.\n\nThe `robots.txt` file only had two lines. It read: `User-agent: *\nSitemap: https://www.cheese.com/sitemap.xml`. This means that is has no restrictions. Presumably this is because it is a relatively low-traffic website.\n\n\n**Part 2:** Learn about the `html_attr()` function from `rvest`. Describe how\nthis function works with a small example.\n\nThis function gets the attributes associated with some HTML elements.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(rvest)\n\nread_html(\"https://www.cheese.com/alphabetical/?per_page=100\") |>\n  html_nodes(\".product-img a img\") |>\n  html_attr(\"class\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  [1] \"image-exists\"  \"image-missing\" \"image-exists\"  \"image-exists\" \n  [5] \"image-exists\"  \"image-exists\"  \"image-missing\" \"image-exists\" \n  [9] \"image-exists\"  \"image-exists\"  \"image-exists\"  \"image-missing\"\n [13] \"image-missing\" \"image-exists\"  \"image-missing\" \"image-missing\"\n [17] \"image-exists\"  \"image-missing\" \"image-exists\"  \"image-missing\"\n [21] \"image-missing\" \"image-missing\" \"image-missing\" \"image-exists\" \n [25] \"image-exists\"  \"image-exists\"  \"image-missing\" \"image-missing\"\n [29] \"image-missing\" \"image-missing\" \"image-missing\" \"image-missing\"\n [33] \"image-exists\"  \"image-missing\" \"image-missing\" \"image-exists\" \n [37] \"image-missing\" \"image-missing\" \"image-missing\" \"image-exists\" \n [41] \"image-exists\"  \"image-exists\"  \"image-exists\"  \"image-exists\" \n [45] \"image-exists\"  \"image-exists\"  \"image-exists\"  \"image-missing\"\n [49] \"image-missing\" \"image-missing\" \"image-missing\" \"image-missing\"\n [53] \"image-missing\" \"image-missing\" \"image-missing\" \"image-exists\" \n [57] \"image-missing\" \"image-missing\" \"image-exists\"  \"image-missing\"\n [61] \"image-missing\" \"image-missing\" \"image-missing\" \"image-missing\"\n [65] \"image-exists\"  \"image-missing\" \"image-exists\"  \"image-exists\" \n [69] \"image-missing\" \"image-missing\" \"image-missing\" \"image-exists\" \n [73] \"image-missing\" \"image-missing\" \"image-missing\" \"image-exists\" \n [77] \"image-exists\"  \"image-exists\"  \"image-missing\" \"image-missing\"\n [81] \"image-exists\"  \"image-exists\"  \"image-missing\" \"image-missing\"\n [85] \"image-exists\"  \"image-exists\"  \"image-missing\" \"image-missing\"\n [89] \"image-exists\"  \"image-missing\" \"image-missing\" \"image-exists\" \n [93] \"image-exists\"  \"image-missing\" \"image-missing\" \"image-missing\"\n [97] \"image-exists\"  \"image-missing\" \"image-missing\" \"image-missing\"\n```\n\n\n:::\n:::\n\n\nThis small example demonstrates how to get whether the image exists for each cheese.\n\n**Part 3:** (Do this alongside Part 4 below.) I \nused [ChatGPT](https://chat.openai.com/chat) to start the process of scraping\ncheese information with the following prompt:\n\n> Write R code using the rvest package that allows me to scrape cheese\n> information from cheese.com.\n\nFully document your process of checking this code. Record any observations you\nmake about where ChatGPT is useful / not useful.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required libraries\nlibrary(rvest)\nlibrary(dplyr)\n\n# Define the URL\nurl <- \"https://www.cheese.com/alphabetical\"\n\n# Read the HTML content from the webpage\nwebpage <- read_html(url)\n\n# Extract the cheese names and URLs\ncheese_data <- webpage %>%\n  html_nodes(\".cheese-item\") %>%\n  html_nodes(\"a\") %>%\n  html_attr(\"href\") %>%\n  paste0(\"https://cheese.com\", .)\n\ncheese_names <- webpage %>%\n  html_nodes(\".cheese-item h3\") %>%\n  html_text()\n\n# Create a data frame to store the results\ncheese_df <- data.frame(\n  Name = cheese_names,\n  URL = cheese_data,\n  stringsAsFactors = FALSE\n)\n\n# Print the data frame\nprint(cheese_df)\n```\n:::\n\n\nThe structure is nominally useful though the LLM appears to be guessing and can't access the page structure.\n\nThe code is easy to read and is transparent for a reader to understand, but it isn't very efficient. The verboseness is communicative, though ultimately unnecessary.\n\n**Part 4:** Obtain the following information for **all** cheeses in the\ndatabase:\n\n-   cheese name\n-   URL for the cheese's webpage (e.g., <https://www.cheese.com/gouda/>)\n-   whether or not the cheese has a picture (e.g., \n[gouda](https://www.cheese.com/gouda/) has a picture, but \n[bianco](https://www.cheese.com/bianco/) does not).\n\nTo be kind to the website owners, please add a 1 second pause between page\nqueries. (Note that you can view 100 cheeses at a time.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparse_page <- function(url, delay = 1) {\n  Sys.sleep(delay)\n\n  # cheese product listings\n  cheeses <- read_html(url) |>\n    html_nodes(\".product-item\")\n\n  # temp object that's used twice\n  nodes <- cheeses |>\n    html_nodes(\"h3 a\")\n\n  # building tibble\n  tibble(\n    name = nodes |> html_text(),\n    url = nodes |>\n      html_attr(\"href\") |>\n      (\\(slug) glue::glue(\"https://www.cheese.com{slug}\"))(),\n    has_image = cheeses |>\n      html_nodes(\".product-img a img\") |>\n      html_attr(\"class\") |>\n      str_detect(\"image-exists\")\n  )\n}\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# can't run this on last page--will find number of pages to parse automatically.\nnum_pages <- \"https://www.cheese.com/alphabetical/?per_page=100\" |>\n  read_html() |>\n  html_nodes(\".pagination a\") |>\n  html_text() |>\n  last() |>\n  as.numeric()\n\ncheeses <- paste0(\n  \"https://www.cheese.com/alphabetical/?per_page=100&page=\",\n  1:num_pages\n) |>\n  map_df(parse_page)\n```\n:::\n\n\n**Part 5:** When you go to a particular cheese's page (like \n[gouda](https://www.cheese.com/gouda/)), you'll see more detailed information\nabout the cheese. For [**just 10**]{.underline} of the cheeses in the database,\nobtain the following detailed information:\n\n-   milk information\n-   country of origin\n-   family\n-   type\n-   flavour\n\n(Just 10 to avoid overtaxing the website! Continue adding a 1 second pause\nbetween page queries.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheese_list <- c(\n  \"https://www.cheese.com/paneer/\",\n  \"https://www.cheese.com/chevre-en-marinade/\",\n  \"https://www.cheese.com/chevre-log/\",\n  \"https://www.cheese.com/goat-gouda/\",\n  \"https://www.cheese.com/gotcha-gouda/\",\n  \"https://www.cheese.com/gouda/\",\n  \"https://www.cheese.com/camembert-des-camarades/\",\n  \"https://www.cheese.com/camembert-de-portneuf/\",\n  \"https://www.cheese.com/camembert-de-normandie/\",\n  \"https://www.cheese.com/camembert/\"\n)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparse_cheese <- function(url, delay = 1) {\n}\n\n\"https://www.cheese.com/camembert-de-normandie/\" |>\n  read_html() |>\n  html_nodes(\".panel-body ul li\") |>\n  html_text(trim = TRUE)\n# sep wider into tibble with NAs and rowbind or use hashmap or something?\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparse_cheese <- function(url, delay = 1) {\n  Sys.sleep(delay)\n  \n  # Read page\n  page <- read_html(url)\n  \n  # Extract bullet point text\n  raw_info <- page %>%\n    html_nodes(\".panel-body ul li\") %>%\n    html_text(trim = TRUE)\n  \n  # Extract milk line separately (doesn't contain \":\")\n  milk_line <- raw_info[grepl(\"^Made from\", raw_info)]\n  milk <- str_remove(milk_line, \"^Made from \")\n\n  # Extract remaining fields that use a colon\n  info_pairs <- raw_info[grepl(\":\", raw_info)] %>%\n    str_split_fixed(\":\", 2) %>%\n    as_tibble() %>%\n    rename(field = V1, value = V2) %>%\n    mutate(\n      field = str_trim(tolower(field)),\n      value = str_trim(value)\n    ) %>%\n    filter(field %in% c(\"country of origin\", \"family\", \"type\", \"flavour\"))\n  \n  # Convert to wide format\n  cheese_info <- pivot_wider(info_pairs, names_from = field, values_from = value)\n  \n  # Add milk column\n  cheese_info <- cheese_info %>%\n    mutate(milk = milk) %>%\n    relocate(milk)\n\n  return(cheese_info)\n}\n\n\ncheese_details <- map_dfr(cheese_list, parse_cheese)\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Nice kable table\n\nlibrary(knitr)\nlibrary(kableExtra)\n\ncheese_details %>%\n  rename(\n    Milk    = milk,\n    Country = `country of origin`,\n    Family  = family,\n    Type    = type,\n    Flavour = flavour\n  ) %>%\n  kable(\n    caption = \"10 Cheeses\",\n    format = \"html\",\n    escape = TRUE\n  ) %>%\n  kable_styling(\n    full_width = FALSE,\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n    position = \"left\"\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"width: auto !important; \">\n<caption>10 Cheeses</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Milk </th>\n   <th style=\"text-align:left;\"> Country </th>\n   <th style=\"text-align:left;\"> Family </th>\n   <th style=\"text-align:left;\"> Type </th>\n   <th style=\"text-align:left;\"> Flavour </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> pasteurized cow's or water buffalo's milk </td>\n   <td style=\"text-align:left;\"> Bangladesh and India </td>\n   <td style=\"text-align:left;\"> Cottage </td>\n   <td style=\"text-align:left;\"> fresh firm </td>\n   <td style=\"text-align:left;\"> milky </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> pasteurized goat's milk </td>\n   <td style=\"text-align:left;\"> United States </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> semi-soft, artisan </td>\n   <td style=\"text-align:left;\"> garlicky, herbaceous, spicy </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> pasteurized goat's milk </td>\n   <td style=\"text-align:left;\"> France </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> fresh soft </td>\n   <td style=\"text-align:left;\"> citrusy </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> pasteurized goat's milk </td>\n   <td style=\"text-align:left;\"> Netherlands </td>\n   <td style=\"text-align:left;\"> Gouda </td>\n   <td style=\"text-align:left;\"> semi-hard, artisan </td>\n   <td style=\"text-align:left;\"> tangy </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> cow's milk </td>\n   <td style=\"text-align:left;\"> United States </td>\n   <td style=\"text-align:left;\"> Gouda </td>\n   <td style=\"text-align:left;\"> semi-hard, artisan </td>\n   <td style=\"text-align:left;\"> sweet, tangy </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> pasteurized or unpasteurized cow's, goat's or sheep's milk </td>\n   <td style=\"text-align:left;\"> Netherlands </td>\n   <td style=\"text-align:left;\"> Gouda </td>\n   <td style=\"text-align:left;\"> hard </td>\n   <td style=\"text-align:left;\"> full-flavored </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> pasteurized cow's milk </td>\n   <td style=\"text-align:left;\"> Canada </td>\n   <td style=\"text-align:left;\"> Camembert </td>\n   <td style=\"text-align:left;\"> soft, soft-ripened </td>\n   <td style=\"text-align:left;\"> buttery, nutty, subtle, sweet </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> pasteurized cow's milk </td>\n   <td style=\"text-align:left;\"> Canada </td>\n   <td style=\"text-align:left;\"> Camembert </td>\n   <td style=\"text-align:left;\"> soft, soft-ripened </td>\n   <td style=\"text-align:left;\"> buttery, creamy </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> unpasteurized cow's milk </td>\n   <td style=\"text-align:left;\"> France </td>\n   <td style=\"text-align:left;\"> Camembert </td>\n   <td style=\"text-align:left;\"> soft, soft-ripened </td>\n   <td style=\"text-align:left;\"> creamy </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> cow's milk </td>\n   <td style=\"text-align:left;\"> France </td>\n   <td style=\"text-align:left;\"> Camembert </td>\n   <td style=\"text-align:left;\"> soft, artisan </td>\n   <td style=\"text-align:left;\"> sweet </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n**Part 6:** Evaluate the code that you wrote in terms of **efficiency**. To\nwhat extent do your function(s) adhere to the **principles for writing good functions**?\nTo what extent are your **functions efficient**? To what extent is your \n**iteration of these functions efficient**? \n\nThe code is efficient. There are few objects saved and pipelines are used extensively to further that goal. Furthermore, leveraging Quartoâ€™s design, we can further bolster efficiency by selectively caching the output of a few cells and make a nice space/time dealâ€“scraping the data takes time due to the number of pages that need to be scraped, so we elected to cache those outputs. Of course, our code still has to run once, but since the targets seem to be static, this allows us to spend some memory to speed up execution time. Since we are caching, we save two objects so as to obviate scraping the site again.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}